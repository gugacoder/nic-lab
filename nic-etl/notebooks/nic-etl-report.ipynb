{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä NIC ETL - Report API\n",
    "\n",
    "## üìã O que este notebook faz\n",
    "\n",
    "Este notebook **exp√µe o relat√≥rio de execu√ß√£o do pipeline** via REST API:\n",
    "\n",
    "- üì• **L√™ o report.json** gerado pelo pipeline ETL\n",
    "- üîç **Valida exist√™ncia** do relat√≥rio\n",
    "- üåê **Retorna via HTTP** para sistemas externos\n",
    "- üìà **Fornece status** da √∫ltima execu√ß√£o do pipeline\n",
    "\n",
    "## üîó Endpoint dispon√≠vel\n",
    "\n",
    "```\n",
    "GET /nic/v1/pipelines/gitlab-qdrant/runs/last\n",
    "```\n",
    "\n",
    "## üìä Resposta esperada\n",
    "\n",
    "Retorna o JSON completo do relat√≥rio com:\n",
    "- Contexto de execu√ß√£o\n",
    "- Status de cada etapa\n",
    "- Valida√ß√£o do fluxo de dados\n",
    "- M√©tricas de performance\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåê Endpoint REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +GET /nic/v1/pipelines/gitlab-qdrant/runs/last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json\nfrom pathlib import Path\nfrom datetime import datetime\n\n# Caminho do relat√≥rio\nreport_path = Path(\"pipeline-data/report.json\")\n\n# Verificar se o relat√≥rio existe\nif not report_path.exists():\n    # Retornar informa√ß√£o de que ainda n√£o foi executado\n    response = {\n        \"pipeline_info\": {\n            \"version\": \"1.0.0\",\n            \"last_execution\": None,\n            \"environment\": \"unknown\"\n        },\n        \"context\": {},\n        \"stages\": [],\n        \"summary\": {\n            \"pipeline_status\": \"NOT_EXECUTED\",\n            \"message\": \"Pipeline has not been executed yet. Please run the ETL pipeline first.\",\n            \"total_duration_seconds\": 0,\n            \"data_flow\": {\n                \"input_files\": 0,\n                \"processed_documents\": 0,\n                \"total_chunks\": 0,\n                \"embeddings_generated\": 0,\n                \"vectors_stored\": 0\n            },\n            \"validation\": {\n                \"overall\": \"NOT_AVAILABLE\"\n            }\n        },\n        \"api_metadata\": {\n            \"endpoint\": \"/nic/v1/pipelines/gitlab-qdrant/runs/last\",\n            \"served_at\": datetime.now().isoformat() + \"Z\",\n            \"report_exists\": False\n        }\n    }\n    print(json.dumps(response, indent=2, ensure_ascii=False))\nelse:\n    # Ler e retornar o relat√≥rio\n    try:\n        with open(report_path, \"r\", encoding=\"utf-8\") as f:\n            report = json.load(f)\n        \n        # Adicionar metadados da API\n        report[\"api_metadata\"] = {\n            \"endpoint\": \"/nic/v1/pipelines/gitlab-qdrant/runs/last\",\n            \"served_at\": datetime.now().isoformat() + \"Z\",\n            \"report_file\": str(report_path),\n            \"report_exists\": True\n        }\n        \n        # Retornar o relat√≥rio completo\n        print(json.dumps(report, indent=2, ensure_ascii=False))\n        \n    except json.JSONDecodeError as e:\n        # Erro ao decodificar JSON\n        response = {\n            \"error\": \"Invalid report format\",\n            \"message\": f\"The report file exists but contains invalid JSON: {str(e)}\",\n            \"status_code\": 500,\n            \"timestamp\": datetime.now().isoformat() + \"Z\"\n        }\n        print(json.dumps(response, indent=2))\n        \n    except Exception as e:\n        # Erro gen√©rico\n        response = {\n            \"error\": \"Internal server error\",\n            \"message\": f\"An error occurred while reading the report: {str(e)}\",\n            \"status_code\": 500,\n            \"timestamp\": datetime.now().isoformat() + \"Z\"\n        }\n        print(json.dumps(response, indent=2))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Endpoint de Estat√≠sticas Resumidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +GET /nic/v1/pipelines/gitlab-qdrant/runs/last/summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json\nfrom pathlib import Path\nfrom datetime import datetime\n\n# Caminho do relat√≥rio\nreport_path = Path(\"pipeline-data/report.json\")\n\nif not report_path.exists():\n    # Retornar resumo vazio quando n√£o executado\n    response = {\n        \"pipeline_status\": \"NOT_EXECUTED\",\n        \"last_execution\": None,\n        \"message\": \"Pipeline has not been executed yet.\",\n        \"total_duration_seconds\": 0,\n        \"data_flow\": {\n            \"input_files\": 0,\n            \"processed_documents\": 0,\n            \"total_chunks\": 0,\n            \"embeddings_generated\": 0,\n            \"vectors_stored\": 0\n        },\n        \"validation\": {\n            \"overall\": \"NOT_AVAILABLE\"\n        },\n        \"api_metadata\": {\n            \"endpoint\": \"/nic/v1/pipelines/gitlab-qdrant/runs/last/summary\",\n            \"served_at\": datetime.now().isoformat() + \"Z\"\n        }\n    }\n    print(json.dumps(response, indent=2))\nelse:\n    try:\n        with open(report_path, \"r\", encoding=\"utf-8\") as f:\n            report = json.load(f)\n        \n        # Extrair apenas o resumo\n        summary = {\n            \"pipeline_status\": report.get(\"summary\", {}).get(\"pipeline_status\", \"UNKNOWN\"),\n            \"last_execution\": report.get(\"pipeline_info\", {}).get(\"last_execution\", \"N/A\"),\n            \"total_duration_seconds\": report.get(\"summary\", {}).get(\"total_duration_seconds\", 0),\n            \"data_flow\": report.get(\"summary\", {}).get(\"data_flow\", {}),\n            \"validation\": report.get(\"summary\", {}).get(\"validation\", {}),\n            \"commit\": report.get(\"context\", {}).get(\"commit\", \"unknown\"),\n            \"api_metadata\": {\n                \"endpoint\": \"/nic/v1/pipelines/gitlab-qdrant/runs/last/summary\",\n                \"served_at\": datetime.now().isoformat() + \"Z\"\n            }\n        }\n        \n        # Adicionar contagem de falhas se houver\n        failed_stages = report.get(\"summary\", {}).get(\"failed_stages\", [])\n        if failed_stages:\n            summary[\"failed_stages\"] = failed_stages\n            summary[\"failure_count\"] = len(failed_stages)\n        \n        print(json.dumps(summary, indent=2, ensure_ascii=False))\n        \n    except Exception as e:\n        response = {\n            \"error\": \"Internal server error\",\n            \"message\": str(e),\n            \"status_code\": 500\n        }\n        print(json.dumps(response, indent=2))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Endpoint de Status por Etapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +GET /nic/v1/pipelines/gitlab-qdrant/runs/last/stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json\nfrom pathlib import Path\nfrom datetime import datetime\n\n# Caminho do relat√≥rio\nreport_path = Path(\"pipeline-data/report.json\")\n\nif not report_path.exists():\n    # Retornar lista vazia quando n√£o executado\n    response = {\n        \"stages\": [],\n        \"total_stages\": 0,\n        \"successful_stages\": 0,\n        \"failed_stages\": 0,\n        \"message\": \"Pipeline has not been executed yet.\",\n        \"api_metadata\": {\n            \"endpoint\": \"/nic/v1/pipelines/gitlab-qdrant/runs/last/stages\",\n            \"served_at\": datetime.now().isoformat() + \"Z\"\n        }\n    }\n    print(json.dumps(response, indent=2))\nelse:\n    try:\n        with open(report_path, \"r\", encoding=\"utf-8\") as f:\n            report = json.load(f)\n        \n        # Extrair informa√ß√µes simplificadas das etapas\n        stages = []\n        for stage in report.get(\"stages\", []):\n            stage_info = {\n                \"stage\": stage[\"stage\"],\n                \"name\": stage[\"name\"],\n                \"status\": stage[\"status\"],\n                \"duration_seconds\": stage.get(\"duration_seconds\", 0)\n            }\n            \n            # Adicionar m√©tricas principais de cada etapa\n            if stage[\"stage\"] == 2:  # GitLab\n                stage_info[\"files_downloaded\"] = stage[\"results\"].get(\"files_downloaded\", 0)\n            elif stage[\"stage\"] == 3:  # Docling\n                stage_info[\"documents_processed\"] = stage[\"results\"].get(\"total_processed\", 0)\n            elif stage[\"stage\"] == 4:  # Chunks\n                stage_info[\"chunks_created\"] = stage[\"results\"].get(\"total_chunks\", 0)\n            elif stage[\"stage\"] == 5:  # Embeddings\n                stage_info[\"embeddings_generated\"] = stage[\"results\"].get(\"embeddings_generated\", 0)\n            elif stage[\"stage\"] == 6:  # Qdrant\n                stage_info[\"vectors_stored\"] = stage[\"results\"].get(\"chunks_inserted\", 0)\n            \n            stages.append(stage_info)\n        \n        response = {\n            \"stages\": stages,\n            \"total_stages\": len(stages),\n            \"successful_stages\": sum(1 for s in stages if s[\"status\"] == \"SUCCESS\"),\n            \"failed_stages\": sum(1 for s in stages if s[\"status\"] == \"FAILED\"),\n            \"api_metadata\": {\n                \"endpoint\": \"/nic/v1/pipelines/gitlab-qdrant/runs/last/stages\",\n                \"served_at\": datetime.now().isoformat() + \"Z\"\n            }\n        }\n        \n        print(json.dumps(response, indent=2, ensure_ascii=False))\n        \n    except Exception as e:\n        response = {\n            \"error\": \"Internal server error\",\n            \"message\": str(e),\n            \"status_code\": 500\n        }\n        print(json.dumps(response, indent=2))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üè• Health Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +GET /nic/v1/pipelines/gitlab-qdrant/health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Verificar sa√∫de do sistema\n",
    "report_path = Path(\"pipeline-data/report.json\")\n",
    "pipeline_data_dir = Path(\"pipeline-data\")\n",
    "\n",
    "health = {\n",
    "    \"status\": \"healthy\",\n",
    "    \"checks\": {\n",
    "        \"report_exists\": report_path.exists(),\n",
    "        \"pipeline_data_exists\": pipeline_data_dir.exists(),\n",
    "        \"documents_dir\": (pipeline_data_dir / \"documents\").exists(),\n",
    "        \"chunks_dir\": (pipeline_data_dir / \"chunks\").exists(),\n",
    "        \"embeddings_dir\": (pipeline_data_dir / \"embeddings\").exists()\n",
    "    },\n",
    "    \"timestamp\": datetime.now().isoformat() + \"Z\"\n",
    "}\n",
    "\n",
    "# Se h√° relat√≥rio, adicionar informa√ß√µes da √∫ltima execu√ß√£o\n",
    "if report_path.exists():\n",
    "    try:\n",
    "        with open(report_path, \"r\") as f:\n",
    "            report = json.load(f)\n",
    "        \n",
    "        health[\"last_pipeline_run\"] = {\n",
    "            \"execution_date\": report.get(\"pipeline_info\", {}).get(\"last_execution\", \"unknown\"),\n",
    "            \"status\": report.get(\"summary\", {}).get(\"pipeline_status\", \"unknown\"),\n",
    "            \"validation\": report.get(\"summary\", {}).get(\"validation\", {}).get(\"overall\", \"unknown\")\n",
    "        }\n",
    "    except:\n",
    "        health[\"last_pipeline_run\"] = {\"status\": \"error_reading_report\"}\n",
    "else:\n",
    "    health[\"last_pipeline_run\"] = {\"status\": \"no_runs_yet\"}\n",
    "\n",
    "# Determinar status geral\n",
    "if not all(health[\"checks\"].values()):\n",
    "    health[\"status\"] = \"degraded\"\n",
    "\n",
    "print(json.dumps(health, indent=2, ensure_ascii=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}