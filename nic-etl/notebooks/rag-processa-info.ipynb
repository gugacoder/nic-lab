{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè¢ RAG: Informa√ß√µes sobre a Processa\n",
    "\n",
    "Este notebook implementa consulta sem√¢ntica ao QDrant para obter informa√ß√µes sobre a Processa Sistemas.\n",
    "\n",
    "## üìã Funcionalidades\n",
    "\n",
    "- Conex√£o com QDrant\n",
    "- Gera√ß√£o de embeddings para query\n",
    "- Busca sem√¢ntica com reranking\n",
    "- Formata√ß√£o de resposta estruturada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Importa√ß√µes e Configura√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any, Optional\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import PointStruct, VectorParams, Distance, Filter, FieldCondition, MatchValue\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from dataclasses import dataclass, asdict\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega configura√ß√µes do ambiente\n",
    "env_file = Path('.env.development')\n",
    "if not env_file.exists():\n",
    "    env_file = Path('.env')\n",
    "    \n",
    "load_dotenv(env_file)\n",
    "\n",
    "# Configura√ß√£o do QDrant\n",
    "QDRANT_URL = os.getenv('QDRANT_URL', 'https://qdrant.codrstudio.dev/')\n",
    "QDRANT_API_KEY = os.getenv('QDRANT_API_KEY')\n",
    "QDRANT_COLLECTION = os.getenv('QDRANT_COLLECTION', 'nic_dev')\n",
    "\n",
    "# Modelo de embeddings\n",
    "EMBEDDING_MODEL = 'BAAI/bge-m3'\n",
    "\n",
    "print(f\"üì° QDrant URL: {QDRANT_URL}\")\n",
    "print(f\"üì¶ Collection: {QDRANT_COLLECTION}\")\n",
    "print(f\"üß† Modelo: {EMBEDDING_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Classe de Busca RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SearchResult:\n",
    "    \"\"\"Resultado de busca estruturado\"\"\"\n",
    "    text: str\n",
    "    score: float\n",
    "    metadata: Dict[str, Any]\n",
    "    source: str\n",
    "    \n",
    "class ProcessaInfoRAG:\n",
    "    \"\"\"Sistema RAG para informa√ß√µes sobre a Processa\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Inicializa conex√µes e modelo\"\"\"\n",
    "        # Conex√£o QDrant\n",
    "        self.client = QdrantClient(\n",
    "            url=QDRANT_URL,\n",
    "            api_key=QDRANT_API_KEY,\n",
    "            timeout=30\n",
    "        )\n",
    "        \n",
    "        # Modelo de embeddings\n",
    "        self.model = SentenceTransformer(EMBEDDING_MODEL)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Configura√ß√µes de busca\n",
    "        self.top_k = 10\n",
    "        self.score_threshold = 0.5\n",
    "        \n",
    "    def generate_embedding(self, text: str) -> np.ndarray:\n",
    "        \"\"\"Gera embedding para texto\"\"\"\n",
    "        with torch.no_grad():\n",
    "            embedding = self.model.encode(\n",
    "                text,\n",
    "                normalize_embeddings=True,\n",
    "                show_progress_bar=False\n",
    "            )\n",
    "        return embedding\n",
    "    \n",
    "    def search_qdrant(self, query: str, limit: int = 10) -> List[SearchResult]:\n",
    "        \"\"\"Busca sem√¢ntica no QDrant\"\"\"\n",
    "        # Gera embedding da query\n",
    "        query_vector = self.generate_embedding(query).tolist()\n",
    "        \n",
    "        # Busca no QDrant\n",
    "        results = self.client.search(\n",
    "            collection_name=QDRANT_COLLECTION,\n",
    "            query_vector=query_vector,\n",
    "            limit=limit,\n",
    "            with_payload=True\n",
    "        )\n",
    "        \n",
    "        # Formata resultados\n",
    "        search_results = []\n",
    "        for hit in results:\n",
    "            if hit.score >= self.score_threshold:\n",
    "                result = SearchResult(\n",
    "                    text=hit.payload.get('text', ''),\n",
    "                    score=hit.score,\n",
    "                    metadata=hit.payload.get('metadata', {}),\n",
    "                    source=hit.payload.get('source', 'unknown')\n",
    "                )\n",
    "                search_results.append(result)\n",
    "                \n",
    "        return search_results\n",
    "    \n",
    "    def rerank_results(self, query: str, results: List[SearchResult]) -> List[SearchResult]:\n",
    "        \"\"\"Reordena resultados por relev√¢ncia\"\"\"\n",
    "        if not results:\n",
    "            return results\n",
    "            \n",
    "        # Calcula scores de cross-encoding para reranking\n",
    "        texts = [r.text for r in results]\n",
    "        pairs = [[query, text] for text in texts]\n",
    "        \n",
    "        # Usa o modelo para calcular similaridade\n",
    "        with torch.no_grad():\n",
    "            query_embedding = self.model.encode(query, normalize_embeddings=True)\n",
    "            text_embeddings = self.model.encode(texts, normalize_embeddings=True)\n",
    "            \n",
    "            # Calcula similaridade cosseno\n",
    "            similarities = np.dot(text_embeddings, query_embedding)\n",
    "        \n",
    "        # Combina scores originais com reranking\n",
    "        for i, result in enumerate(results):\n",
    "            combined_score = (result.score * 0.7) + (similarities[i] * 0.3)\n",
    "            result.score = float(combined_score)\n",
    "        \n",
    "        # Reordena por score combinado\n",
    "        results.sort(key=lambda x: x.score, reverse=True)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_processa_info(self, query: str = \"Quem √© a Processa Sistemas\") -> Dict[str, Any]:\n",
    "        \"\"\"Obt√©m informa√ß√µes sobre a Processa\"\"\"\n",
    "        try:\n",
    "            # Busca inicial\n",
    "            results = self.search_qdrant(query, limit=self.top_k)\n",
    "            \n",
    "            if not results:\n",
    "                return {\n",
    "                    \"status\": \"no_results\",\n",
    "                    \"message\": \"Nenhuma informa√ß√£o encontrada sobre a Processa\",\n",
    "                    \"query\": query,\n",
    "                    \"timestamp\": datetime.now().isoformat()\n",
    "                }\n",
    "            \n",
    "            # Reranking\n",
    "            results = self.rerank_results(query, results)\n",
    "            \n",
    "            # Extrai informa√ß√µes principais\n",
    "            top_results = results[:5]  # Top 5 mais relevantes\n",
    "            \n",
    "            # Monta resposta estruturada\n",
    "            response = {\n",
    "                \"status\": \"success\",\n",
    "                \"query\": query,\n",
    "                \"company_info\": {\n",
    "                    \"name\": \"Processa Sistemas\",\n",
    "                    \"description\": self._extract_description(top_results),\n",
    "                    \"key_points\": self._extract_key_points(top_results),\n",
    "                    \"sources\": self._extract_sources(top_results)\n",
    "                },\n",
    "                \"search_metadata\": {\n",
    "                    \"total_results\": len(results),\n",
    "                    \"top_score\": float(results[0].score) if results else 0,\n",
    "                    \"collection\": QDRANT_COLLECTION,\n",
    "                    \"model\": EMBEDDING_MODEL\n",
    "                },\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"message\": str(e),\n",
    "                \"query\": query,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "    \n",
    "    def _extract_description(self, results: List[SearchResult]) -> str:\n",
    "        \"\"\"Extrai descri√ß√£o consolidada\"\"\"\n",
    "        if not results:\n",
    "            return \"Informa√ß√£o n√£o dispon√≠vel\"\n",
    "        \n",
    "        # Pega o texto mais relevante\n",
    "        main_text = results[0].text\n",
    "        \n",
    "        # Limita tamanho\n",
    "        if len(main_text) > 500:\n",
    "            main_text = main_text[:497] + \"...\"\n",
    "            \n",
    "        return main_text\n",
    "    \n",
    "    def _extract_key_points(self, results: List[SearchResult]) -> List[str]:\n",
    "        \"\"\"Extrai pontos principais\"\"\"\n",
    "        key_points = []\n",
    "        seen = set()\n",
    "        \n",
    "        for result in results:\n",
    "            # Extrai frases importantes\n",
    "            sentences = result.text.split('.')\n",
    "            for sentence in sentences[:2]:  # Primeiras 2 frases\n",
    "                sentence = sentence.strip()\n",
    "                if sentence and len(sentence) > 20 and sentence not in seen:\n",
    "                    key_points.append(sentence)\n",
    "                    seen.add(sentence)\n",
    "                    \n",
    "                if len(key_points) >= 5:\n",
    "                    break\n",
    "                    \n",
    "            if len(key_points) >= 5:\n",
    "                break\n",
    "                \n",
    "        return key_points\n",
    "    \n",
    "    def _extract_sources(self, results: List[SearchResult]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Extrai fontes dos documentos\"\"\"\n",
    "        sources = []\n",
    "        seen_sources = set()\n",
    "        \n",
    "        for result in results[:5]:\n",
    "            source_name = result.source\n",
    "            if source_name not in seen_sources:\n",
    "                sources.append({\n",
    "                    \"document\": source_name,\n",
    "                    \"relevance_score\": float(result.score),\n",
    "                    \"metadata\": result.metadata\n",
    "                })\n",
    "                seen_sources.add(source_name)\n",
    "                \n",
    "        return sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Fun√ß√µes para Integra√ß√£o com API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inst√¢ncia global para reutiliza√ß√£o\n",
    "_rag_instance = None\n",
    "\n",
    "def get_rag_instance() -> ProcessaInfoRAG:\n",
    "    \"\"\"Retorna inst√¢ncia singleton do RAG\"\"\"\n",
    "    global _rag_instance\n",
    "    if _rag_instance is None:\n",
    "        _rag_instance = ProcessaInfoRAG()\n",
    "    return _rag_instance\n",
    "\n",
    "def get_processa_info_api(custom_query: Optional[str] = None) -> Dict[str, Any]:\n",
    "    \"\"\"Fun√ß√£o principal para uso em API\"\"\"\n",
    "    rag = get_rag_instance()\n",
    "    \n",
    "    # Query padr√£o ou customizada\n",
    "    query = custom_query or \"Quem √© a Processa Sistemas\"\n",
    "    \n",
    "    # Busca informa√ß√µes\n",
    "    result = rag.get_processa_info(query)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def search_processa_documents(query: str, limit: int = 5) -> Dict[str, Any]:\n",
    "    \"\"\"Busca gen√©rica em documentos sobre a Processa\"\"\"\n",
    "    rag = get_rag_instance()\n",
    "    \n",
    "    try:\n",
    "        # Busca\n",
    "        results = rag.search_qdrant(query, limit=limit * 2)\n",
    "        \n",
    "        # Reranking\n",
    "        results = rag.rerank_results(query, results)\n",
    "        \n",
    "        # Formata resposta\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"query\": query,\n",
    "            \"results\": [\n",
    "                {\n",
    "                    \"text\": r.text[:300] + \"...\" if len(r.text) > 300 else r.text,\n",
    "                    \"score\": float(r.score),\n",
    "                    \"source\": r.source,\n",
    "                    \"metadata\": r.metadata\n",
    "                }\n",
    "                for r in results[:limit]\n",
    "            ],\n",
    "            \"total_found\": len(results),\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"message\": str(e),\n",
    "            \"query\": query,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Teste do Sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_processa_rag():\n",
    "    \"\"\"Testa o sistema RAG\"\"\"\n",
    "    print(\"üß™ Testando RAG Processa Info\\n\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Teste 1: Query padr√£o\n",
    "    print(\"\\nüìç Teste 1: Query padr√£o\")\n",
    "    result = get_processa_info_api()\n",
    "    \n",
    "    if result['status'] == 'success':\n",
    "        print(\"‚úÖ Busca realizada com sucesso!\")\n",
    "        print(f\"\\nüìù Descri√ß√£o encontrada:\")\n",
    "        print(result['company_info']['description'][:200] + \"...\")\n",
    "        print(f\"\\nüéØ Pontos principais: {len(result['company_info']['key_points'])} encontrados\")\n",
    "        print(f\"üìö Fontes: {len(result['company_info']['sources'])} documentos\")\n",
    "    else:\n",
    "        print(f\"‚ùå Erro: {result.get('message', 'Desconhecido')}\")\n",
    "    \n",
    "    # Teste 2: Query customizada\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"\\nüìç Teste 2: Query customizada\")\n",
    "    custom_result = search_processa_documents(\"servi√ßos da Processa\", limit=3)\n",
    "    \n",
    "    if custom_result['status'] == 'success':\n",
    "        print(\"‚úÖ Busca customizada realizada!\")\n",
    "        print(f\"\\nüìä Resultados encontrados: {custom_result['total_found']}\")\n",
    "        print(f\"üîù Top {len(custom_result['results'])} resultados retornados\")\n",
    "        \n",
    "        if custom_result['results']:\n",
    "            print(f\"\\nü•á Melhor resultado (score: {custom_result['results'][0]['score']:.3f}):\")\n",
    "            print(custom_result['results'][0]['text'][:150] + \"...\")\n",
    "    else:\n",
    "        print(f\"‚ùå Erro: {custom_result.get('message', 'Desconhecido')}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"\\n‚ú® Testes conclu√≠dos!\")\n",
    "\n",
    "# Executa teste\n",
    "if __name__ == \"__main__\":\n",
    "    test_processa_rag()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Exporta√ß√£o de Fun√ß√µes para API\n",
    "\n",
    "As fun√ß√µes abaixo s√£o exportadas para uso no notebook `rest-api.ipynb`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√µes p√∫blicas para API\n",
    "__all__ = [\n",
    "    'get_processa_info_api',\n",
    "    'search_processa_documents',\n",
    "    'ProcessaInfoRAG'\n",
    "]\n",
    "\n",
    "print(\"‚úÖ Notebook RAG Processa Info carregado com sucesso!\")\n",
    "print(\"\\nüìå Fun√ß√µes dispon√≠veis:\")\n",
    "print(\"  - get_processa_info_api(): Obt√©m informa√ß√µes sobre a Processa\")\n",
    "print(\"  - search_processa_documents(query, limit): Busca gen√©rica em documentos\")\n",
    "print(\"\\nüîó Para integrar com API, importe este notebook no rest-api.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}