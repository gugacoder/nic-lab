{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”ª SEGMENTAÃ‡ÃƒO EM CHUNKS\n",
    "\n",
    "Divide o texto em segmentos para processamento de embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk size: 500 tokens\n",
      "Overlap: 100 tokens\n",
      "Documentos encontrados: 31\n",
      "  30-Aprovados/Mapas/VisÃ£o Geral do Self Checkout.md\n",
      "  30-Aprovados/Mapas/VisÃ£o Geral do NIC.md\n",
      "  30-Aprovados/Mapas/Processa Sistemas.md\n",
      "  30-Aprovados/TÃ³picos/Cancelamento de cupom.md\n",
      "  30-Aprovados/TÃ³picos/SolicitaÃ§Ã£o de ajuda.md\n",
      "  30-Aprovados/TÃ³picos/HistÃ³rico de atualizaÃ§Ãµes Self Checkout.md\n",
      "  30-Aprovados/TÃ³picos/Funcionalidade do bloqueio.md\n",
      "  30-Aprovados/TÃ³picos/AplicaÃ§Ã£o de desconto por item.md\n",
      "  30-Aprovados/TÃ³picos/PropÃ³sito do NIC.md\n",
      "  30-Aprovados/TÃ³picos/ReimpressÃ£o do Ãºltimo cupom.md\n",
      "  ... e mais 21 documentos\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import json\n",
    "\n",
    "# ConfiguraÃ§Ã£o\n",
    "CHUNK_SIZE = int(os.getenv(\"CHUNK_SIZE\", \"500\"))\n",
    "CHUNK_OVERLAP = int(os.getenv(\"CHUNK_OVERLAP\", \"100\"))\n",
    "\n",
    "# DiretÃ³rios\n",
    "processed_dir = Path(\"pipeline_data/processed\")\n",
    "chunks_dir = Path(\"pipeline_data/chunks\")\n",
    "chunks_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Limpar diretÃ³rio chunks recursivamente\n",
    "for f in chunks_dir.rglob(\"*\"):\n",
    "    if f.is_file():\n",
    "        f.unlink()\n",
    "\n",
    "print(f\"Chunk size: {CHUNK_SIZE} tokens\")\n",
    "print(f\"Overlap: {CHUNK_OVERLAP} tokens\")\n",
    "\n",
    "# Listar documentos processados recursivamente com caminhos relativos\n",
    "documents = [str(doc.relative_to(processed_dir)) for doc in processed_dir.rglob(\"*.md\")]\n",
    "\n",
    "print(f\"Documentos encontrados: {len(documents)}\")\n",
    "\n",
    "for i, doc in enumerate(documents[:10]):\n",
    "    print(f\"  {doc}\")\n",
    "\n",
    "if len(documents) > 10:\n",
    "    print(f\"  ... e mais {len(documents) - 10} documentos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… 51 chunks criados para: 30-Aprovados/Mapas/VisÃ£o Geral do Self Checkout.md\n",
      "  âœ… 15 chunks criados para: 30-Aprovados/Mapas/VisÃ£o Geral do NIC.md\n",
      "  âœ… 13 chunks criados para: 30-Aprovados/Mapas/Processa Sistemas.md\n",
      "  âœ… 7 chunks criados para: 30-Aprovados/TÃ³picos/Cancelamento de cupom.md\n",
      "  âœ… 6 chunks criados para: 30-Aprovados/TÃ³picos/SolicitaÃ§Ã£o de ajuda.md\n",
      "  âœ… 5 chunks criados para: 30-Aprovados/TÃ³picos/HistÃ³rico de atualizaÃ§Ãµes Self Checkout.md\n",
      "  âœ… 11 chunks criados para: 30-Aprovados/TÃ³picos/Funcionalidade do bloqueio.md\n",
      "  âœ… 7 chunks criados para: 30-Aprovados/TÃ³picos/AplicaÃ§Ã£o de desconto por item.md\n",
      "  âœ… 12 chunks criados para: 30-Aprovados/TÃ³picos/PropÃ³sito do NIC.md\n",
      "  âœ… 4 chunks criados para: 30-Aprovados/TÃ³picos/ReimpressÃ£o do Ãºltimo cupom.md\n",
      "  âœ… 8 chunks criados para: 30-Aprovados/TÃ³picos/FunÃ§Ã£o do Chat NIC.md\n",
      "  âœ… 9 chunks criados para: 30-Aprovados/TÃ³picos/Acesso ao menu do fiscal.md\n",
      "  âœ… 10 chunks criados para: 30-Aprovados/TÃ³picos/Cronograma e marcos do projeto.md\n",
      "  âœ… 7 chunks criados para: 30-Aprovados/TÃ³picos/Efetuar pagamento.md\n",
      "  âœ… 5 chunks criados para: 30-Aprovados/TÃ³picos/Cancelamento de item.md\n",
      "  âœ… 7 chunks criados para: 30-Aprovados/TÃ³picos/OperaÃ§Ã£o contÃ­nua e evoluÃ§Ã£o do sistema.md\n",
      "  âœ… 12 chunks criados para: 30-Aprovados/TÃ³picos/Finalidade e visÃ£o do NIC.md\n",
      "  âœ… 2 chunks criados para: 30-Aprovados/TÃ³picos/Iniciar a compra.md\n",
      "  âœ… 8 chunks criados para: 30-Aprovados/TÃ³picos/Processo de documentaÃ§Ã£o e validaÃ§Ã£o.md\n",
      "  âœ… 9 chunks criados para: 30-Aprovados/TÃ³picos/Infraestrutura tÃ©cnica e operacional.md\n",
      "  âœ… 7 chunks criados para: 30-Aprovados/TÃ³picos/ApresentaÃ§Ã£o do sistema Self Checkout.md\n",
      "  âœ… 8 chunks criados para: 30-Aprovados/TÃ³picos/Retornar para registro de venda.md\n",
      "  âœ… 19 chunks criados para: 30-Aprovados/TÃ³picos/Componentes principais do sistema.md\n",
      "  âœ… 10 chunks criados para: 30-Aprovados/TÃ³picos/Registro de produtos.md\n",
      "  âœ… 17 chunks criados para: 30-Aprovados/TÃ³picos/PrÃ©-requisitos tÃ©cnicos.md\n",
      "  âœ… 8 chunks criados para: 30-Aprovados/TÃ³picos/Estrutura e fluxo da base de conhecimento.md\n",
      "  âœ… 5 chunks criados para: 30-Aprovados/TÃ³picos/FinalizaÃ§Ã£o do movimento diÃ¡rio.md\n",
      "  âœ… 6 chunks criados para: 30-Aprovados/TÃ³picos/IdentificaÃ§Ã£o do cliente.md\n",
      "  âœ… 10 chunks criados para: 30-Aprovados/TÃ³picos/GovernanÃ§a e papÃ©is organizacionais.md\n",
      "  âœ… 15 chunks criados para: 30-Aprovados/TÃ³picos/PadrÃµes de DocumentaÃ§Ã£o do NIC.md\n",
      "  âœ… 9 chunks criados para: 30-Aprovados/TÃ³picos/EstratÃ©gia de implantaÃ§Ã£o e adoÃ§Ã£o.md\n",
      "\n",
      "ðŸ“Š Total de chunks: 322\n"
     ]
    }
   ],
   "source": [
    "# Processar cada arquivo\n",
    "all_chunks = []\n",
    "chunk_id = 0\n",
    "\n",
    "for text_file in documents:\n",
    "    try:\n",
    "        # Construir caminho completo para leitura\n",
    "        full_path = processed_dir / text_file\n",
    "        \n",
    "        # Ler texto\n",
    "        with open(full_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text_content = f.read()\n",
    "        \n",
    "        if not text_content.strip():\n",
    "            print(f\"  âš ï¸ Arquivo vazio: {Path(text_file).name}\")\n",
    "            continue\n",
    "        \n",
    "        # Dividir em chunks\n",
    "        chunks = text_splitter.split_text(text_content)\n",
    "        \n",
    "        # Processar cada chunk\n",
    "        for i, chunk_text in enumerate(chunks):\n",
    "            chunk_data = {\n",
    "                \"chunk_id\": chunk_id,\n",
    "                \"source_document\": text_file.replace(\".md\", \"\"),  # Usa caminho relativo sem extensÃ£o\n",
    "                \"chunk_index\": i,\n",
    "                \"text\": chunk_text.strip(),\n",
    "                \"char_count\": len(chunk_text)\n",
    "            }\n",
    "            \n",
    "            # Adicionar ao array com estrutura mais clara\n",
    "            all_chunks.append(chunk_data)\n",
    "            \n",
    "            chunk_id += 1\n",
    "        \n",
    "        print(f\"  âœ… {len(chunks)} chunks criados para: {text_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ Erro: {str(e)}\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Total de chunks: {len(all_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’¾ Chunks salvos em: pipeline_data/chunks/chunks.jsonl\n",
      "ðŸ“Š Total de chunks no arquivo: 322\n",
      "\n",
      "ðŸ“ˆ EstatÃ­sticas:\n",
      "  Total chunks: 322\n",
      "  Tamanho mÃ©dio: 350 caracteres\n",
      "  Tamanho mÃ­nimo: 13 caracteres\n",
      "  Tamanho mÃ¡ximo: 500 caracteres\n",
      "\n",
      "ðŸ“ DistribuiÃ§Ã£o de chunks por arquivo:\n",
      "  30-Aprovados/Mapas/VisÃ£o Geral do Self Checkout: 51 chunks\n",
      "  30-Aprovados/TÃ³picos/Componentes principais do sistema: 19 chunks\n",
      "  30-Aprovados/TÃ³picos/PrÃ©-requisitos tÃ©cnicos: 17 chunks\n",
      "  30-Aprovados/Mapas/VisÃ£o Geral do NIC: 15 chunks\n",
      "  30-Aprovados/TÃ³picos/PadrÃµes de DocumentaÃ§Ã£o do NIC: 15 chunks\n",
      "  30-Aprovados/Mapas/Processa Sistemas: 13 chunks\n",
      "  30-Aprovados/TÃ³picos/PropÃ³sito do NIC: 12 chunks\n",
      "  30-Aprovados/TÃ³picos/Finalidade e visÃ£o do NIC: 12 chunks\n",
      "  30-Aprovados/TÃ³picos/Funcionalidade do bloqueio: 11 chunks\n",
      "  30-Aprovados/TÃ³picos/Cronograma e marcos do projeto: 10 chunks\n",
      "  ... e mais 21 arquivos\n"
     ]
    }
   ],
   "source": [
    "# Salvar todos os chunks em um Ãºnico arquivo JSONL\n",
    "jsonl_file = chunks_dir / \"chunks.jsonl\"\n",
    "with open(jsonl_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for chunk in all_chunks:\n",
    "        f.write(json.dumps(chunk, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"\\nðŸ’¾ Chunks salvos em: {jsonl_file}\")\n",
    "print(f\"ðŸ“Š Total de chunks no arquivo: {len(all_chunks)}\")\n",
    "\n",
    "# EstatÃ­sticas\n",
    "if all_chunks:\n",
    "    avg_chars = sum(chunk[\"char_count\"] for chunk in all_chunks) / len(all_chunks)\n",
    "    max_chars = max(chunk[\"char_count\"] for chunk in all_chunks)\n",
    "    min_chars = min(chunk[\"char_count\"] for chunk in all_chunks)\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ EstatÃ­sticas:\")\n",
    "    print(f\"  Total chunks: {len(all_chunks)}\")\n",
    "    print(f\"  Tamanho mÃ©dio: {avg_chars:.0f} caracteres\")\n",
    "    print(f\"  Tamanho mÃ­nimo: {min_chars} caracteres\")\n",
    "    print(f\"  Tamanho mÃ¡ximo: {max_chars} caracteres\")\n",
    "    \n",
    "    # Mostrar distribuiÃ§Ã£o por arquivo\n",
    "    from collections import Counter\n",
    "    \n",
    "    print(f\"\\nðŸ“ DistribuiÃ§Ã£o de chunks por arquivo:\")\n",
    "    # Usar source_document que jÃ¡ estÃ¡ no chunk\n",
    "    file_counter = Counter(chunk[\"source_document\"] for chunk in all_chunks)\n",
    "    \n",
    "    # Mostrar top 10 arquivos com mais chunks\n",
    "    for file, count in file_counter.most_common(10):\n",
    "        print(f\"  {file}: {count} chunks\")\n",
    "    \n",
    "    if len(file_counter) > 10:\n",
    "        print(f\"  ... e mais {len(file_counter) - 10} arquivos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
