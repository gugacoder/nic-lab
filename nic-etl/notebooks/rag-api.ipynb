{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîç RAG API - Sistema de Busca Sem√¢ntica\n",
    "\n",
    "## üìã O que este notebook faz\n",
    "\n",
    "Este notebook implementa um **sistema completo de RAG (Retrieval-Augmented Generation)** com busca sem√¢ntica h√≠brida:\n",
    "\n",
    "- üîç **Busca vetorial** usando embeddings BAAI/bge-m3\n",
    "- üè∑Ô∏è **Filtros por metadata** (repo, branch, arquivo, data)\n",
    "- üéØ **Pesquisa h√≠brida** combinando vetores e metadata\n",
    "- ‚ö° **Cache inteligente** para queries frequentes\n",
    "- üìä **Reranking** e scoring avan√ßado\n",
    "\n",
    "## üåê Endpoints Dispon√≠veis\n",
    "\n",
    "### Busca Principal\n",
    "- `GET /api/v1/search` - Busca sem√¢ntica h√≠brida\n",
    "- `POST /api/v1/search` - Busca com payload complexo\n",
    "\n",
    "### Busca Especializada  \n",
    "- `GET /api/v1/search/similar/{point_id}` - Documentos similares\n",
    "- `GET /api/v1/search/metadata` - Busca apenas por metadata\n",
    "\n",
    "### Utilit√°rios\n",
    "- `GET /api/v1/search/stats` - Estat√≠sticas da collection\n",
    "- `GET /api/v1/search/test` - Teste de conectividade\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Configura√ß√£o e Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Configura√ß√£o:\n",
      "  Qdrant URL: http://qdrant.codrstudio.dev:6333\n",
      "  Collection: nic\n",
      "  Modelo: BAAI/bge-m3\n",
      "  API Key: ***d857\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Optional, Any\n",
    "from collections import defaultdict\n",
    "from functools import lru_cache\n",
    "\n",
    "# Qdrant\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import (\n",
    "    Distance, VectorParams, PointStruct,\n",
    "    Filter, FieldCondition, MatchValue, \n",
    "    FilterSelector, Range\n",
    ")\n",
    "\n",
    "# Embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Configura√ß√£o do ambiente\n",
    "QDRANT_URL = os.getenv(\"QDRANT_URL\", \"http://qdrant.codrstudio.dev:6333\")\n",
    "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")\n",
    "COLLECTION_NAME = os.getenv(\"QDRANT_COLLECTION\", \"nic\")\n",
    "\n",
    "# Modelo de embeddings (mesmo do pipeline)\n",
    "EMBEDDING_MODEL = os.getenv(\"EMBEDDING_MODEL\", \"BAAI/bge-m3\")\n",
    "\n",
    "# Par√¢metros de busca\n",
    "DEFAULT_TOP_K = 5\n",
    "DEFAULT_SCORE_THRESHOLD = 0.7\n",
    "MAX_TOP_K = 20\n",
    "\n",
    "# Cache\n",
    "CACHE_TTL = 300  # 5 minutos\n",
    "query_cache = {}\n",
    "\n",
    "print(f\"üîß Configura√ß√£o:\")\n",
    "print(f\"  Qdrant URL: {QDRANT_URL}\")\n",
    "print(f\"  Collection: {COLLECTION_NAME}\")\n",
    "print(f\"  Modelo: {EMBEDDING_MODEL}\")\n",
    "print(f\"  API Key: ***{QDRANT_API_KEY[-4:] if QDRANT_API_KEY and len(QDRANT_API_KEY) > 4 else '???'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîó Conex√£o com Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Conectado ao Qdrant\n",
      "üìä Collection 'nic':\n",
      "  Pontos: 644\n",
      "  Status: green\n",
      "  Vetores: 1024 dimens√µes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1190128/4169790996.py:3: UserWarning: Api key is used with an insecure connection.\n",
      "  client = QdrantClient(\n"
     ]
    }
   ],
   "source": [
    "# Inicializar cliente Qdrant\n",
    "try:\n",
    "    client = QdrantClient(\n",
    "        url=QDRANT_URL,\n",
    "        api_key=QDRANT_API_KEY\n",
    "    )\n",
    "    \n",
    "    # Verificar collection\n",
    "    collection_info = client.get_collection(COLLECTION_NAME)\n",
    "    \n",
    "    print(f\"‚úÖ Conectado ao Qdrant\")\n",
    "    print(f\"üìä Collection '{COLLECTION_NAME}':\")\n",
    "    print(f\"  Pontos: {collection_info.points_count}\")\n",
    "    print(f\"  Status: {collection_info.status}\")\n",
    "    print(f\"  Vetores: {collection_info.config.params.vectors.size} dimens√µes\")\n",
    "    \n",
    "    VECTOR_SIZE = collection_info.config.params.vectors.size\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro ao conectar ao Qdrant: {e}\")\n",
    "    print(f\"   Verifique as configura√ß√µes no .env\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Modelo de Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Carregando modelo BAAI/bge-m3...\n",
      "‚úÖ Modelo carregado: 1024 dimens√µes\n",
      "üìè Embedding de teste: 1024 dimens√µes\n",
      "üìä Magnitude: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Carregar modelo (com cache singleton)\n",
    "_model_instance = None\n",
    "\n",
    "def get_embedding_model():\n",
    "    \"\"\"Retorna inst√¢ncia singleton do modelo de embeddings\"\"\"\n",
    "    global _model_instance\n",
    "    if _model_instance is None:\n",
    "        print(f\"ü§ñ Carregando modelo {EMBEDDING_MODEL}...\")\n",
    "        _model_instance = SentenceTransformer(EMBEDDING_MODEL)\n",
    "        print(f\"‚úÖ Modelo carregado: {_model_instance.get_sentence_embedding_dimension()} dimens√µes\")\n",
    "    return _model_instance\n",
    "\n",
    "def generate_embedding(text: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Gera embedding normalizado para um texto\n",
    "    \"\"\"\n",
    "    model = get_embedding_model()\n",
    "    embedding = model.encode(\n",
    "        text,\n",
    "        normalize_embeddings=True,\n",
    "        show_progress_bar=False\n",
    "    )\n",
    "    return embedding.tolist()\n",
    "\n",
    "# Teste do modelo\n",
    "test_embedding = generate_embedding(\"teste de embedding\")\n",
    "print(f\"üìè Embedding de teste: {len(test_embedding)} dimens√µes\")\n",
    "print(f\"üìä Magnitude: {np.linalg.norm(test_embedding):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üè∑Ô∏è Constru√ß√£o de Filtros de Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè∑Ô∏è Filtro de teste criado: True\n"
     ]
    }
   ],
   "source": [
    "def build_metadata_filter(filters: Optional[Dict[str, Any]] = None) -> Optional[Filter]:\n",
    "    \"\"\"\n",
    "    Constr√≥i filtros Qdrant a partir de par√¢metros de busca.\n",
    "    \n",
    "    Filtros suportados:\n",
    "    - repo: string (reposit√≥rio GitLab)\n",
    "    - branch: string (branch do Git)\n",
    "    - relpath: string (caminho relativo do arquivo)\n",
    "    - source_document: string (nome do documento)\n",
    "    - lang: string (idioma: pt-BR, en)\n",
    "    - date_from: string (ISO date)\n",
    "    - date_to: string (ISO date)\n",
    "    - embed_model_major: string (vers√£o do modelo)\n",
    "    \"\"\"\n",
    "    if not filters:\n",
    "        return None\n",
    "    \n",
    "    conditions = []\n",
    "    \n",
    "    # Filtros de string exata\n",
    "    string_fields = ['repo', 'branch', 'relpath', 'source_document', 'lang', 'embed_model_major']\n",
    "    for field in string_fields:\n",
    "        if field in filters and filters[field]:\n",
    "            conditions.append(\n",
    "                FieldCondition(\n",
    "                    key=field,\n",
    "                    match=MatchValue(value=filters[field])\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    # Filtro de range de datas\n",
    "    if 'date_from' in filters or 'date_to' in filters:\n",
    "        date_range = {}\n",
    "        if 'date_from' in filters:\n",
    "            date_range['gte'] = filters['date_from']\n",
    "        if 'date_to' in filters:\n",
    "            date_range['lte'] = filters['date_to']\n",
    "        \n",
    "        conditions.append(\n",
    "            FieldCondition(\n",
    "                key='last_updated',\n",
    "                range=Range(**date_range)\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    if conditions:\n",
    "        return Filter(must=conditions)\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Teste de filtros\n",
    "test_filter = build_metadata_filter({\n",
    "    'repo': 'nic/documentacao/base-de-conhecimento',\n",
    "    'branch': 'main'\n",
    "})\n",
    "print(f\"üè∑Ô∏è Filtro de teste criado: {test_filter is not None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Fun√ß√£o Principal de Busca H√≠brida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Teste de busca:\n",
      "  Resultados: 0\n",
      "  Tempo: 164.04ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1190128/3475715252.py:44: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_results = client.search(\n"
     ]
    }
   ],
   "source": [
    "def hybrid_search(\n",
    "    query: str,\n",
    "    top_k: int = DEFAULT_TOP_K,\n",
    "    score_threshold: float = DEFAULT_SCORE_THRESHOLD,\n",
    "    filters: Optional[Dict[str, Any]] = None,\n",
    "    include_context: bool = False\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Realiza busca h√≠brida no Qdrant.\n",
    "    \n",
    "    Args:\n",
    "        query: Texto da pesquisa\n",
    "        top_k: N√∫mero de resultados (max: 20)\n",
    "        score_threshold: Score m√≠nimo (0-1)\n",
    "        filters: Filtros de metadata\n",
    "        include_context: Se deve incluir chunks adjacentes\n",
    "    \n",
    "    Returns:\n",
    "        Dicion√°rio com resultados e metadata\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Validar par√¢metros\n",
    "    top_k = min(top_k, MAX_TOP_K)\n",
    "    \n",
    "    # Verificar cache\n",
    "    cache_key = hashlib.md5(\n",
    "        f\"{query}:{top_k}:{score_threshold}:{json.dumps(filters or {}, sort_keys=True)}\".encode()\n",
    "    ).hexdigest()\n",
    "    \n",
    "    if cache_key in query_cache:\n",
    "        cached_result, cached_time = query_cache[cache_key]\n",
    "        if time.time() - cached_time < CACHE_TTL:\n",
    "            cached_result['from_cache'] = True\n",
    "            return cached_result\n",
    "    \n",
    "    # Gerar embedding da query\n",
    "    query_embedding = generate_embedding(query)\n",
    "    \n",
    "    # Construir filtros\n",
    "    search_filter = build_metadata_filter(filters)\n",
    "    \n",
    "    # Buscar no Qdrant\n",
    "    search_results = client.search(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        query_vector=query_embedding,\n",
    "        query_filter=search_filter,\n",
    "        limit=top_k,\n",
    "        score_threshold=score_threshold,\n",
    "        with_payload=True,\n",
    "        with_vectors=False\n",
    "    )\n",
    "    \n",
    "    # Formatar resultados\n",
    "    results = []\n",
    "    for hit in search_results:\n",
    "        result = {\n",
    "            'score': round(hit.score, 4),\n",
    "            'text': hit.payload.get('text', ''),\n",
    "            'metadata': {\n",
    "                'chunk_id': hit.payload.get('chunk_id'),\n",
    "                'chunk_index': hit.payload.get('chunk_index'),\n",
    "                'source_document': hit.payload.get('source_document'),\n",
    "                'repo': hit.payload.get('repo'),\n",
    "                'branch': hit.payload.get('branch'),\n",
    "                'commit': hit.payload.get('commit'),\n",
    "                'last_updated': hit.payload.get('last_updated')\n",
    "            },\n",
    "            'point_id': hit.id\n",
    "        }\n",
    "        \n",
    "        # Adicionar highlights (palavras da query no texto)\n",
    "        highlights = []\n",
    "        query_words = query.lower().split()\n",
    "        text_lower = result['text'].lower()\n",
    "        for word in query_words:\n",
    "            if len(word) > 2 and word in text_lower:\n",
    "                # Encontrar contexto da palavra\n",
    "                idx = text_lower.index(word)\n",
    "                start = max(0, idx - 30)\n",
    "                end = min(len(result['text']), idx + len(word) + 30)\n",
    "                highlight = result['text'][start:end]\n",
    "                if start > 0:\n",
    "                    highlight = '...' + highlight\n",
    "                if end < len(result['text']):\n",
    "                    highlight = highlight + '...'\n",
    "                highlights.append(highlight)\n",
    "        \n",
    "        if highlights:\n",
    "            result['highlights'] = highlights[:3]  # Max 3 highlights\n",
    "        \n",
    "        results.append(result)\n",
    "    \n",
    "    # Preparar resposta\n",
    "    response = {\n",
    "        'query': query,\n",
    "        'total_results': len(results),\n",
    "        'results': results,\n",
    "        'search_metadata': {\n",
    "            'model': EMBEDDING_MODEL,\n",
    "            'collection': COLLECTION_NAME,\n",
    "            'top_k': top_k,\n",
    "            'score_threshold': score_threshold,\n",
    "            'filters_applied': filters or {},\n",
    "            'search_time_ms': round((time.time() - start_time) * 1000, 2),\n",
    "            'from_cache': False\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Adicionar ao cache\n",
    "    query_cache[cache_key] = (response, time.time())\n",
    "    \n",
    "    # Limpar cache antigo\n",
    "    if len(query_cache) > 100:\n",
    "        # Remover entradas mais antigas\n",
    "        sorted_cache = sorted(query_cache.items(), key=lambda x: x[1][1])\n",
    "        for key, _ in sorted_cache[:50]:\n",
    "            del query_cache[key]\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Teste da busca\n",
    "test_result = hybrid_search(\n",
    "    query=\"self checkout\",\n",
    "    top_k=3\n",
    ")\n",
    "print(f\"üîç Teste de busca:\")\n",
    "print(f\"  Resultados: {test_result['total_results']}\")\n",
    "print(f\"  Tempo: {test_result['search_metadata']['search_time_ms']}ms\")\n",
    "if test_result['results']:\n",
    "    print(f\"  Melhor score: {test_result['results'][0]['score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåê Endpoint: Busca Principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"query\": \"self checkout\",\n",
      "  \"total_results\": 0,\n",
      "  \"results\": [],\n",
      "  \"search_metadata\": {\n",
      "    \"model\": \"BAAI/bge-m3\",\n",
      "    \"collection\": \"nic\",\n",
      "    \"top_k\": 5,\n",
      "    \"score_threshold\": 0.7,\n",
      "    \"filters_applied\": {},\n",
      "    \"search_time_ms\": 138.77,\n",
      "    \"from_cache\": false\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1190128/3475715252.py:44: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_results = client.search(\n"
     ]
    }
   ],
   "source": [
    "# GET /api/v1/search\n",
    "import sys\n",
    "import urllib.parse\n",
    "\n",
    "# Parse query parameters\n",
    "def parse_query_params():\n",
    "    \"\"\"Parse query parameters from REQUEST global\"\"\"\n",
    "    try:\n",
    "        # Acessar REQUEST global do Jupyter Kernel Gateway\n",
    "        request = REQUEST\n",
    "        query_string = request.get('query', {})\n",
    "        \n",
    "        # Extrair par√¢metros\n",
    "        query = query_string.get('q', [''])[0]\n",
    "        top_k = int(query_string.get('top_k', [DEFAULT_TOP_K])[0])\n",
    "        score_threshold = float(query_string.get('score_threshold', [DEFAULT_SCORE_THRESHOLD])[0])\n",
    "        \n",
    "        # Filtros opcionais\n",
    "        filters = {}\n",
    "        for key in ['repo', 'branch', 'relpath', 'source_document', 'lang']:\n",
    "            if key in query_string:\n",
    "                filters[key] = query_string[key][0]\n",
    "        \n",
    "        return query, top_k, score_threshold, filters\n",
    "        \n",
    "    except (NameError, KeyError):\n",
    "        # Fallback para teste local\n",
    "        return \"self checkout\", 5, 0.7, {}\n",
    "\n",
    "# Executar busca\n",
    "query, top_k, score_threshold, filters = parse_query_params()\n",
    "\n",
    "if not query:\n",
    "    response = {\n",
    "        'error': 'Query parameter \"q\" is required',\n",
    "        'example': '/api/v1/search?q=self+checkout&top_k=5'\n",
    "    }\n",
    "else:\n",
    "    response = hybrid_search(\n",
    "        query=query,\n",
    "        top_k=top_k,\n",
    "        score_threshold=score_threshold,\n",
    "        filters=filters if filters else None\n",
    "    )\n",
    "\n",
    "# Retornar JSON\n",
    "print(json.dumps(response, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåê Endpoint: Busca POST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"query\": \"self checkout pagamento\",\n",
      "  \"total_results\": 0,\n",
      "  \"results\": [],\n",
      "  \"search_metadata\": {\n",
      "    \"model\": \"BAAI/bge-m3\",\n",
      "    \"collection\": \"nic\",\n",
      "    \"top_k\": 5,\n",
      "    \"score_threshold\": 0.7,\n",
      "    \"filters_applied\": {\n",
      "      \"branch\": \"main\"\n",
      "    },\n",
      "    \"search_time_ms\": 102.96,\n",
      "    \"from_cache\": false\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1190128/3475715252.py:44: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_results = client.search(\n"
     ]
    }
   ],
   "source": [
    "# POST /api/v1/search\n",
    "import sys\n",
    "\n",
    "def parse_post_body():\n",
    "    \"\"\"Parse JSON body from POST request\"\"\"\n",
    "    try:\n",
    "        # Acessar REQUEST global do Jupyter Kernel Gateway\n",
    "        request = REQUEST\n",
    "        body = request.get('body', '{}')\n",
    "        return json.loads(body)\n",
    "    except (NameError, json.JSONDecodeError):\n",
    "        # Fallback para teste\n",
    "        return {\n",
    "            'query': 'self checkout pagamento',\n",
    "            'top_k': 5,\n",
    "            'filters': {'branch': 'main'}\n",
    "        }\n",
    "\n",
    "# Parse request body\n",
    "request_data = parse_post_body()\n",
    "\n",
    "# Validar campos obrigat√≥rios\n",
    "if 'query' not in request_data:\n",
    "    response = {\n",
    "        'error': 'Field \"query\" is required in request body',\n",
    "        'example': {\n",
    "            'query': 'texto de busca',\n",
    "            'top_k': 5,\n",
    "            'score_threshold': 0.7,\n",
    "            'filters': {\n",
    "                'repo': 'nic/documentacao',\n",
    "                'branch': 'main'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "else:\n",
    "    # Executar busca\n",
    "    response = hybrid_search(\n",
    "        query=request_data['query'],\n",
    "        top_k=request_data.get('top_k', DEFAULT_TOP_K),\n",
    "        score_threshold=request_data.get('score_threshold', DEFAULT_SCORE_THRESHOLD),\n",
    "        filters=request_data.get('filters'),\n",
    "        include_context=request_data.get('include_context', False)\n",
    "    )\n",
    "\n",
    "print(json.dumps(response, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Endpoint: Busca por Similaridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET /api/v1/search/similar/<point_id>\n",
    "def find_similar_documents(\n",
    "    point_id: int,\n",
    "    top_k: int = DEFAULT_TOP_K,\n",
    "    score_threshold: float = 0.8\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Encontra documentos similares a um documento existente.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Buscar o ponto original\n",
    "        original_points = client.retrieve(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            ids=[point_id],\n",
    "            with_vectors=True,\n",
    "            with_payload=True\n",
    "        )\n",
    "        \n",
    "        if not original_points:\n",
    "            return {\n",
    "                'error': f'Point {point_id} not found',\n",
    "                'point_id': point_id\n",
    "            }\n",
    "        \n",
    "        original = original_points[0]\n",
    "        \n",
    "        # Buscar similares usando o vetor do documento\n",
    "        similar_results = client.search(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            query_vector=original.vector,\n",
    "            limit=top_k + 1,  # +1 porque o pr√≥prio documento ser√° retornado\n",
    "            score_threshold=score_threshold,\n",
    "            with_payload=True,\n",
    "            with_vectors=False\n",
    "        )\n",
    "        \n",
    "        # Filtrar o pr√≥prio documento dos resultados\n",
    "        results = []\n",
    "        for hit in similar_results:\n",
    "            if hit.id != point_id:\n",
    "                results.append({\n",
    "                    'score': round(hit.score, 4),\n",
    "                    'text': hit.payload.get('text', '')[:200] + '...',\n",
    "                    'metadata': {\n",
    "                        'chunk_id': hit.payload.get('chunk_id'),\n",
    "                        'source_document': hit.payload.get('source_document'),\n",
    "                        'chunk_index': hit.payload.get('chunk_index')\n",
    "                    },\n",
    "                    'point_id': hit.id\n",
    "                })\n",
    "        \n",
    "        return {\n",
    "            'original': {\n",
    "                'point_id': point_id,\n",
    "                'text': original.payload.get('text', '')[:200] + '...',\n",
    "                'source_document': original.payload.get('source_document')\n",
    "            },\n",
    "            'similar_documents': results[:top_k],\n",
    "            'total_similar': len(results),\n",
    "            'search_metadata': {\n",
    "                'collection': COLLECTION_NAME,\n",
    "                'score_threshold': score_threshold,\n",
    "                'search_time_ms': round((time.time() - start_time) * 1000, 2)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'error': str(e),\n",
    "            'point_id': point_id\n",
    "        }\n",
    "\n",
    "# Teste (usar um ID real da collection)\n",
    "# similar_result = find_similar_documents(12345, top_k=3)\n",
    "# print(json.dumps(similar_result, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Endpoint: Busca por Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Busca por metadata:\n",
      "  Total pontos: 10\n",
      "  Documentos: 8\n"
     ]
    }
   ],
   "source": [
    "# GET /api/v1/search/metadata\n",
    "def search_by_metadata(\n",
    "    filters: Dict[str, Any],\n",
    "    limit: int = 20,\n",
    "    offset: int = 0\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Busca apenas por filtros de metadata, sem usar vetores.\n",
    "    √ötil para listar documentos de um reposit√≥rio/branch espec√≠fico.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if not filters:\n",
    "        return {\n",
    "            'error': 'At least one filter is required',\n",
    "            'available_filters': [\n",
    "                'repo', 'branch', 'relpath', 'source_document', \n",
    "                'lang', 'date_from', 'date_to'\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    # Construir filtro\n",
    "    search_filter = build_metadata_filter(filters)\n",
    "    \n",
    "    if not search_filter:\n",
    "        return {\n",
    "            'error': 'Invalid filters provided',\n",
    "            'filters': filters\n",
    "        }\n",
    "    \n",
    "    # Buscar com scroll (pagina√ß√£o)\n",
    "    results, next_offset = client.scroll(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        scroll_filter=search_filter,\n",
    "        limit=limit,\n",
    "        offset=offset,\n",
    "        with_payload=True,\n",
    "        with_vectors=False\n",
    "    )\n",
    "    \n",
    "    # Agrupar por documento\n",
    "    documents = defaultdict(list)\n",
    "    for point in results:\n",
    "        doc_name = point.payload.get('source_document', 'unknown')\n",
    "        documents[doc_name].append({\n",
    "            'chunk_index': point.payload.get('chunk_index'),\n",
    "            'text_preview': point.payload.get('text', '')[:100] + '...',\n",
    "            'point_id': point.id\n",
    "        })\n",
    "    \n",
    "    # Formatar resposta\n",
    "    response = {\n",
    "        'filters': filters,\n",
    "        'total_points': len(results),\n",
    "        'documents': [\n",
    "            {\n",
    "                'source_document': doc,\n",
    "                'chunks_count': len(chunks),\n",
    "                'chunks': sorted(chunks, key=lambda x: x['chunk_index'])[:3]  # Primeiros 3 chunks\n",
    "            }\n",
    "            for doc, chunks in documents.items()\n",
    "        ],\n",
    "        'pagination': {\n",
    "            'limit': limit,\n",
    "            'offset': offset,\n",
    "            'has_more': next_offset is not None,\n",
    "            'next_offset': next_offset\n",
    "        },\n",
    "        'search_metadata': {\n",
    "            'collection': COLLECTION_NAME,\n",
    "            'search_time_ms': round((time.time() - start_time) * 1000, 2)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Teste\n",
    "metadata_result = search_by_metadata(\n",
    "    filters={'branch': 'main'},\n",
    "    limit=10\n",
    ")\n",
    "print(f\"üìä Busca por metadata:\")\n",
    "print(f\"  Total pontos: {metadata_result.get('total_points', 0)}\")\n",
    "print(f\"  Documentos: {len(metadata_result.get('documents', []))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Endpoint: Estat√≠sticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"collection\": {\n",
      "    \"name\": \"nic\",\n",
      "    \"points_count\": 644,\n",
      "    \"status\": \"green\",\n",
      "    \"vector_size\": 1024,\n",
      "    \"distance_metric\": \"COSINE\"\n",
      "  },\n",
      "  \"model\": {\n",
      "    \"name\": \"BAAI/bge-m3\",\n",
      "    \"dimensions\": 1024\n",
      "  },\n",
      "  \"search_config\": {\n",
      "    \"default_top_k\": 5,\n",
      "    \"max_top_k\": 20,\n",
      "    \"default_score_threshold\": 0.7\n",
      "  },\n",
      "  \"cache\": {\n",
      "    \"entries\": 3,\n",
      "    \"ttl_seconds\": 300,\n",
      "    \"max_entries\": 100\n",
      "  },\n",
      "  \"available_metadata_fields\": [\n",
      "    \"chunk_id\",\n",
      "    \"chunk_index\",\n",
      "    \"text\",\n",
      "    \"char_count\",\n",
      "    \"repo\",\n",
      "    \"branch\",\n",
      "    \"relpath\",\n",
      "    \"source_document\",\n",
      "    \"commit\",\n",
      "    \"last_updated\",\n",
      "    \"embed_model_major\",\n",
      "    \"embed_model_full\",\n",
      "    \"tokenizer_major\",\n",
      "    \"tokenizer_full\",\n",
      "    \"embedding_model\",\n",
      "    \"content_sha256\",\n",
      "    \"lang\",\n",
      "    \"processing_date\",\n",
      "    \"pipeline_version\"\n",
      "  ],\n",
      "  \"api_version\": \"1.0.0\",\n",
      "  \"timestamp\": \"2025-08-18T20:55:23.863359Z\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# GET /api/v1/search/stats\n",
    "def get_collection_stats() -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Retorna estat√≠sticas da collection e do sistema de busca.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Informa√ß√µes da collection\n",
    "        collection_info = client.get_collection(COLLECTION_NAME)\n",
    "        \n",
    "        # Estat√≠sticas de cache\n",
    "        cache_stats = {\n",
    "            'entries': len(query_cache),\n",
    "            'ttl_seconds': CACHE_TTL,\n",
    "            'max_entries': 100\n",
    "        }\n",
    "        \n",
    "        # Exemplo de busca para mostrar campos dispon√≠veis\n",
    "        sample_points = client.scroll(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            limit=1,\n",
    "            with_payload=True,\n",
    "            with_vectors=False\n",
    "        )[0]\n",
    "        \n",
    "        available_fields = []\n",
    "        if sample_points:\n",
    "            available_fields = list(sample_points[0].payload.keys())\n",
    "        \n",
    "        return {\n",
    "            'collection': {\n",
    "                'name': COLLECTION_NAME,\n",
    "                'points_count': collection_info.points_count,\n",
    "                'status': collection_info.status,\n",
    "                'vector_size': collection_info.config.params.vectors.size,\n",
    "                'distance_metric': 'COSINE'\n",
    "            },\n",
    "            'model': {\n",
    "                'name': EMBEDDING_MODEL,\n",
    "                'dimensions': VECTOR_SIZE\n",
    "            },\n",
    "            'search_config': {\n",
    "                'default_top_k': DEFAULT_TOP_K,\n",
    "                'max_top_k': MAX_TOP_K,\n",
    "                'default_score_threshold': DEFAULT_SCORE_THRESHOLD\n",
    "            },\n",
    "            'cache': cache_stats,\n",
    "            'available_metadata_fields': available_fields,\n",
    "            'api_version': '1.0.0',\n",
    "            'timestamp': datetime.now().isoformat() + 'Z'\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'error': str(e),\n",
    "            'collection': COLLECTION_NAME\n",
    "        }\n",
    "\n",
    "# Executar\n",
    "stats = get_collection_stats()\n",
    "print(json.dumps(stats, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Endpoint: Teste de Conectividade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status\": \"healthy\",\n",
      "  \"tests\": {\n",
      "    \"qdrant_connection\": true,\n",
      "    \"collection_exists\": true,\n",
      "    \"model_loaded\": true,\n",
      "    \"embedding_generation\": true,\n",
      "    \"search_capability\": true\n",
      "  },\n",
      "  \"errors\": null,\n",
      "  \"environment\": {\n",
      "    \"qdrant_url\": \"http://qdrant.codrstudio.dev:6333\",\n",
      "    \"collection\": \"nic\",\n",
      "    \"model\": \"BAAI/bge-m3\"\n",
      "  },\n",
      "  \"timestamp\": \"2025-08-18T20:55:24.104979Z\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1190128/3475715252.py:44: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_results = client.search(\n"
     ]
    }
   ],
   "source": [
    "# GET /api/v1/search/test\n",
    "def test_connectivity() -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Testa conectividade com Qdrant e funcionalidades b√°sicas.\n",
    "    \"\"\"\n",
    "    tests = {\n",
    "        'qdrant_connection': False,\n",
    "        'collection_exists': False,\n",
    "        'model_loaded': False,\n",
    "        'embedding_generation': False,\n",
    "        'search_capability': False\n",
    "    }\n",
    "    \n",
    "    errors = []\n",
    "    \n",
    "    # Teste 1: Conex√£o Qdrant\n",
    "    try:\n",
    "        client.get_collections()\n",
    "        tests['qdrant_connection'] = True\n",
    "    except Exception as e:\n",
    "        errors.append(f\"Qdrant connection: {str(e)}\")\n",
    "    \n",
    "    # Teste 2: Collection existe\n",
    "    try:\n",
    "        client.get_collection(COLLECTION_NAME)\n",
    "        tests['collection_exists'] = True\n",
    "    except Exception as e:\n",
    "        errors.append(f\"Collection check: {str(e)}\")\n",
    "    \n",
    "    # Teste 3: Modelo carregado\n",
    "    try:\n",
    "        model = get_embedding_model()\n",
    "        tests['model_loaded'] = True\n",
    "    except Exception as e:\n",
    "        errors.append(f\"Model loading: {str(e)}\")\n",
    "    \n",
    "    # Teste 4: Gera√ß√£o de embedding\n",
    "    try:\n",
    "        test_embedding = generate_embedding(\"teste\")\n",
    "        if len(test_embedding) == VECTOR_SIZE:\n",
    "            tests['embedding_generation'] = True\n",
    "    except Exception as e:\n",
    "        errors.append(f\"Embedding generation: {str(e)}\")\n",
    "    \n",
    "    # Teste 5: Capacidade de busca\n",
    "    try:\n",
    "        result = hybrid_search(\"teste\", top_k=1)\n",
    "        if 'results' in result:\n",
    "            tests['search_capability'] = True\n",
    "    except Exception as e:\n",
    "        errors.append(f\"Search test: {str(e)}\")\n",
    "    \n",
    "    # Resultado geral\n",
    "    all_passed = all(tests.values())\n",
    "    \n",
    "    return {\n",
    "        'status': 'healthy' if all_passed else 'unhealthy',\n",
    "        'tests': tests,\n",
    "        'errors': errors if errors else None,\n",
    "        'environment': {\n",
    "            'qdrant_url': QDRANT_URL,\n",
    "            'collection': COLLECTION_NAME,\n",
    "            'model': EMBEDDING_MODEL\n",
    "        },\n",
    "        'timestamp': datetime.now().isoformat() + 'Z'\n",
    "    }\n",
    "\n",
    "# Executar teste\n",
    "test_result = test_connectivity()\n",
    "print(json.dumps(test_result, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Documenta√ß√£o OpenAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö OpenAPI Spec:\n",
      "  Endpoints: 5\n",
      "    - /api/v1/search\n",
      "    - /api/v1/search/similar/{point_id}\n",
      "    - /api/v1/search/metadata\n",
      "    - /api/v1/search/stats\n",
      "    - /api/v1/search/test\n"
     ]
    }
   ],
   "source": [
    "# GET /api/v1/search/openapi\n",
    "def get_openapi_spec() -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Retorna especifica√ß√£o OpenAPI para os endpoints de busca.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"openapi\": \"3.0.0\",\n",
    "        \"info\": {\n",
    "            \"title\": \"NIC RAG API\",\n",
    "            \"description\": \"API de busca sem√¢ntica e retrieval para o sistema NIC\",\n",
    "            \"version\": \"1.0.0\"\n",
    "        },\n",
    "        \"paths\": {\n",
    "            \"/api/v1/search\": {\n",
    "                \"get\": {\n",
    "                    \"summary\": \"Busca sem√¢ntica h√≠brida\",\n",
    "                    \"parameters\": [\n",
    "                        {\n",
    "                            \"name\": \"q\",\n",
    "                            \"in\": \"query\",\n",
    "                            \"required\": True,\n",
    "                            \"schema\": {\"type\": \"string\"},\n",
    "                            \"description\": \"Texto da busca\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"name\": \"top_k\",\n",
    "                            \"in\": \"query\",\n",
    "                            \"schema\": {\"type\": \"integer\", \"default\": 5, \"maximum\": 20},\n",
    "                            \"description\": \"N√∫mero de resultados\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"name\": \"score_threshold\",\n",
    "                            \"in\": \"query\",\n",
    "                            \"schema\": {\"type\": \"number\", \"default\": 0.7, \"minimum\": 0, \"maximum\": 1},\n",
    "                            \"description\": \"Score m√≠nimo de similaridade\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"name\": \"repo\",\n",
    "                            \"in\": \"query\",\n",
    "                            \"schema\": {\"type\": \"string\"},\n",
    "                            \"description\": \"Filtrar por reposit√≥rio\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"name\": \"branch\",\n",
    "                            \"in\": \"query\",\n",
    "                            \"schema\": {\"type\": \"string\"},\n",
    "                            \"description\": \"Filtrar por branch\"\n",
    "                        }\n",
    "                    ],\n",
    "                    \"responses\": {\n",
    "                        \"200\": {\n",
    "                            \"description\": \"Resultados da busca\",\n",
    "                            \"content\": {\n",
    "                                \"application/json\": {\n",
    "                                    \"schema\": {\n",
    "                                        \"type\": \"object\",\n",
    "                                        \"properties\": {\n",
    "                                            \"query\": {\"type\": \"string\"},\n",
    "                                            \"total_results\": {\"type\": \"integer\"},\n",
    "                                            \"results\": {\n",
    "                                                \"type\": \"array\",\n",
    "                                                \"items\": {\n",
    "                                                    \"type\": \"object\",\n",
    "                                                    \"properties\": {\n",
    "                                                        \"score\": {\"type\": \"number\"},\n",
    "                                                        \"text\": {\"type\": \"string\"},\n",
    "                                                        \"metadata\": {\"type\": \"object\"},\n",
    "                                                        \"highlights\": {\"type\": \"array\"}\n",
    "                                                    }\n",
    "                                                }\n",
    "                                            },\n",
    "                                            \"search_metadata\": {\"type\": \"object\"}\n",
    "                                        }\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"post\": {\n",
    "                    \"summary\": \"Busca com payload complexo\",\n",
    "                    \"requestBody\": {\n",
    "                        \"required\": True,\n",
    "                        \"content\": {\n",
    "                            \"application/json\": {\n",
    "                                \"schema\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"required\": [\"query\"],\n",
    "                                    \"properties\": {\n",
    "                                        \"query\": {\"type\": \"string\"},\n",
    "                                        \"top_k\": {\"type\": \"integer\"},\n",
    "                                        \"score_threshold\": {\"type\": \"number\"},\n",
    "                                        \"filters\": {\"type\": \"object\"},\n",
    "                                        \"include_context\": {\"type\": \"boolean\"}\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"/api/v1/search/similar/{point_id}\": {\n",
    "                \"get\": {\n",
    "                    \"summary\": \"Buscar documentos similares\",\n",
    "                    \"parameters\": [\n",
    "                        {\n",
    "                            \"name\": \"point_id\",\n",
    "                            \"in\": \"path\",\n",
    "                            \"required\": True,\n",
    "                            \"schema\": {\"type\": \"integer\"}\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            \"/api/v1/search/metadata\": {\n",
    "                \"get\": {\n",
    "                    \"summary\": \"Busca apenas por metadata\"\n",
    "                }\n",
    "            },\n",
    "            \"/api/v1/search/stats\": {\n",
    "                \"get\": {\n",
    "                    \"summary\": \"Estat√≠sticas da collection\"\n",
    "                }\n",
    "            },\n",
    "            \"/api/v1/search/test\": {\n",
    "                \"get\": {\n",
    "                    \"summary\": \"Teste de conectividade\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Mostrar spec\n",
    "openapi = get_openapi_spec()\n",
    "print(f\"üìö OpenAPI Spec:\")\n",
    "print(f\"  Endpoints: {len(openapi['paths'])}\")\n",
    "for path in openapi['paths']:\n",
    "    print(f\"    - {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Exemplos de Uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Exemplos de uso da API RAG:\n",
      "\n",
      "1Ô∏è‚É£ Busca simples:\n",
      "   GET /api/v1/search?q=self+checkout\n",
      "\n",
      "2Ô∏è‚É£ Busca com filtros:\n",
      "   GET /api/v1/search?q=pagamento&branch=main&top_k=10\n",
      "\n",
      "3Ô∏è‚É£ Busca POST:\n",
      "   POST /api/v1/search\n",
      "   Body: {\n",
      "    \"query\": \"identifica\\u00e7\\u00e3o do cliente\",\n",
      "    \"top_k\": 5,\n",
      "    \"score_threshold\": 0.8,\n",
      "    \"filters\": {\n",
      "        \"repo\": \"nic/documentacao/base-de-conhecimento\",\n",
      "        \"branch\": \"main\"\n",
      "    },\n",
      "    \"include_context\": true\n",
      "}\n",
      "\n",
      "4Ô∏è‚É£ Documentos similares:\n",
      "   GET /api/v1/search/similar/12345\n",
      "\n",
      "5Ô∏è‚É£ Busca por metadata:\n",
      "   GET /api/v1/search/metadata?branch=main&repo=nic/documentacao\n",
      "\n",
      "6Ô∏è‚É£ Estat√≠sticas:\n",
      "   GET /api/v1/search/stats\n",
      "\n",
      "‚úÖ API RAG pronta para uso!\n"
     ]
    }
   ],
   "source": [
    "# Exemplos de queries para teste\n",
    "print(\"üß™ Exemplos de uso da API RAG:\\n\")\n",
    "\n",
    "# 1. Busca simples\n",
    "print(\"1Ô∏è‚É£ Busca simples:\")\n",
    "print(\"   GET /api/v1/search?q=self+checkout\\n\")\n",
    "\n",
    "# 2. Busca com filtros\n",
    "print(\"2Ô∏è‚É£ Busca com filtros:\")\n",
    "print(\"   GET /api/v1/search?q=pagamento&branch=main&top_k=10\\n\")\n",
    "\n",
    "# 3. Busca POST com payload complexo\n",
    "print(\"3Ô∏è‚É£ Busca POST:\")\n",
    "post_example = {\n",
    "    \"query\": \"identifica√ß√£o do cliente\",\n",
    "    \"top_k\": 5,\n",
    "    \"score_threshold\": 0.8,\n",
    "    \"filters\": {\n",
    "        \"repo\": \"nic/documentacao/base-de-conhecimento\",\n",
    "        \"branch\": \"main\"\n",
    "    },\n",
    "    \"include_context\": True\n",
    "}\n",
    "print(f\"   POST /api/v1/search\")\n",
    "print(f\"   Body: {json.dumps(post_example, indent=4)}\\n\")\n",
    "\n",
    "# 4. Busca por similaridade\n",
    "print(\"4Ô∏è‚É£ Documentos similares:\")\n",
    "print(\"   GET /api/v1/search/similar/12345\\n\")\n",
    "\n",
    "# 5. Busca por metadata\n",
    "print(\"5Ô∏è‚É£ Busca por metadata:\")\n",
    "print(\"   GET /api/v1/search/metadata?branch=main&repo=nic/documentacao\\n\")\n",
    "\n",
    "# 6. Estat√≠sticas\n",
    "print(\"6Ô∏è‚É£ Estat√≠sticas:\")\n",
    "print(\"   GET /api/v1/search/stats\\n\")\n",
    "\n",
    "print(\"‚úÖ API RAG pronta para uso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
