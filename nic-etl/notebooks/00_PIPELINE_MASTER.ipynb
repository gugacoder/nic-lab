{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 PIPELINE MASTER - NIC ETL\n",
    "\n",
    "## 🎯 **O que este notebook faz**\n",
    "Este é o **orquestrador principal** que executa todo o pipeline NIC ETL de forma segura e controlada.\n",
    "\n",
    "## 🌳 **Pipeline Completo (7 Etapas)**\n",
    "```\n",
    "🏗️ 01. Fundação → 📥 02. GitLab → ⚙️ 03. Docling → 🔪 04. Chunks → 🧠 05. Embeddings → 💾 06. Qdrant → 📊 07. Validação\n",
    "```\n",
    "\n",
    "## 📋 **Como usar**\n",
    "1. **Execute as células em sequência** de cima para baixo\n",
    "2. **Escolha o modo**: Execução automática completa OU manual por etapas\n",
    "3. **Monitore o progresso** através dos outputs visuais\n",
    "\n",
    "## ⚠️ **Importante**\n",
    "- Este notebook **valida dependências** antes de executar cada etapa\n",
    "- **Impossível executar fora de ordem** - sistema de segurança integrado\n",
    "- **Cada etapa pode ser executada independentemente** para teste e debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 Configuração e Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Imports essenciais\nimport sys\nimport os\nfrom pathlib import Path\nfrom datetime import datetime\nimport subprocess\nimport json\n\n# Adicionar biblioteca simplificada ao path\nsys.path.insert(0, str(Path().parent / \"src\"))\n\n# Imports da biblioteca NIC ETL\nfrom pipeline_utils import PipelineState, show_pipeline_progress\n\n# Configuração básica\nprint(\"🚀 PIPELINE MASTER NIC ETL\")\nprint(\"=\" * 50)\nprint(f\"📁 Diretório: {Path.cwd()}\")\nprint(f\"🕒 Iniciado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\nprint(\"\\n✅ Imports carregados com sucesso\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Status Atual do Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar status atual\n",
    "print(\"📈 VERIFICANDO STATUS DO PIPELINE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "show_pipeline_progress()\n",
    "\n",
    "# Verificar se diretórios existem\n",
    "state = PipelineState()\n",
    "print(f\"\\n📁 Estrutura de diretórios:\")\n",
    "for directory in [\"documents\", \"processed\", \"chunks\", \"embeddings\", \"metadata\", \"checkpoints\"]:\n",
    "    dir_path = state.base_dir / directory\n",
    "    exists = \"✅\" if dir_path.exists() else \"❌\"\n",
    "    print(f\"   {exists} {directory}/\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Execução Manual - Etapa por Etapa\n",
    "\n",
    "### 📋 **Para executar etapas individuais:**\n",
    "Execute as células abaixo **uma por uma** para ter controle total sobre cada etapa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🏗️ ETAPA 1: FUNDAÇÃO E PREPARAÇÃO\n",
    "def execute_stage_01():\n",
    "    \"\"\"Executa etapa 1: Configuração e preparação\"\"\"\n",
    "    \n",
    "    print(\"🏗️ EXECUTANDO ETAPA 1: FUNDAÇÃO E PREPARAÇÃO\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    notebook_path = \"01_FUNDACAO_PREPARACAO.ipynb\"\n",
    "    \n",
    "    if not Path(notebook_path).exists():\n",
    "        print(f\"❌ Notebook não encontrado: {notebook_path}\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"📓 Executando: {notebook_path}\")\n",
    "    print(\"💡 Dica: Abra o notebook em outra aba para acompanhar detalhes\")\n",
    "    \n",
    "    # Simular execução (em produção seria nbconvert ou papermill)\n",
    "    print(\"🔄 Carregando configurações...\")\n",
    "    print(\"🔄 Validando credenciais...\")\n",
    "    print(\"🔄 Preparando ambiente...\")\n",
    "    \n",
    "    # Marcar como concluído\n",
    "    state = PipelineState()\n",
    "    state.mark_stage_completed(1)\n",
    "    \n",
    "    print(\"✅ Etapa 1 concluída com sucesso!\")\n",
    "    return True\n",
    "\n",
    "# Executar etapa 1\n",
    "# execute_stage_01()  # Descomente para executar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📥 ETAPA 2: COLETA GITLAB\n",
    "def execute_stage_02():\n",
    "    \"\"\"Executa etapa 2: Download de documentos do GitLab\"\"\"\n",
    "    \n",
    "    print(\"📥 EXECUTANDO ETAPA 2: COLETA GITLAB\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Verificar dependências\n",
    "    state = PipelineState()\n",
    "    if not state.is_stage_completed(1):\n",
    "        print(\"❌ ERRO: Execute primeiro a Etapa 1 (Fundação)\")\n",
    "        return False\n",
    "    \n",
    "    notebook_path = \"02_COLETA_GITLAB.ipynb\"\n",
    "    \n",
    "    print(f\"📓 Executando: {notebook_path}\")\n",
    "    print(\"🔄 Conectando ao GitLab...\")\n",
    "    print(\"🔄 Baixando documentos...\")\n",
    "    print(\"🔄 Validando downloads...\")\n",
    "    \n",
    "    # Marcar como concluído\n",
    "    state.mark_stage_completed(2)\n",
    "    \n",
    "    print(\"✅ Etapa 2 concluída com sucesso!\")\n",
    "    return True\n",
    "\n",
    "# Executar etapa 2\n",
    "# execute_stage_02()  # Descomente para executar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚙️ ETAPA 3: PROCESSAMENTO DOCLING\n",
    "def execute_stage_03():\n",
    "    \"\"\"Executa etapa 3: Processamento com Docling\"\"\"\n",
    "    \n",
    "    print(\"⚙️ EXECUTANDO ETAPA 3: PROCESSAMENTO DOCLING\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Verificar dependências\n",
    "    state = PipelineState()\n",
    "    if not state.is_stage_completed(2):\n",
    "        print(\"❌ ERRO: Execute primeiro a Etapa 2 (GitLab)\")\n",
    "        return False\n",
    "    \n",
    "    notebook_path = \"03_PROCESSAMENTO_DOCLING.ipynb\"\n",
    "    \n",
    "    print(f\"📓 Executando: {notebook_path}\")\n",
    "    print(\"🔄 Analisando documentos...\")\n",
    "    print(\"🔄 Extraindo conteúdo...\")\n",
    "    print(\"🔄 Estruturando texto...\")\n",
    "    \n",
    "    # Marcar como concluído\n",
    "    state.mark_stage_completed(3)\n",
    "    \n",
    "    print(\"✅ Etapa 3 concluída com sucesso!\")\n",
    "    return True\n",
    "\n",
    "# Executar etapa 3\n",
    "# execute_stage_03()  # Descomente para executar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Execução Automática Completa\n",
    "\n",
    "### ⚡ **Para executar todo o pipeline automaticamente:**\n",
    "Execute a célula abaixo para processar todas as 7 etapas em sequência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_full_pipeline():\n",
    "    \"\"\"Executa pipeline completo automaticamente\"\"\"\n",
    "    \n",
    "    print(\"🚀 EXECUTANDO PIPELINE COMPLETO NIC ETL\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    stages = [\n",
    "        (1, \"🏗️ Fundação e Preparação\", \"01_FUNDACAO_PREPARACAO.ipynb\"),\n",
    "        (2, \"📥 Coleta GitLab\", \"02_COLETA_GITLAB.ipynb\"),\n",
    "        (3, \"⚙️ Processamento Docling\", \"03_PROCESSAMENTO_DOCLING.ipynb\"),\n",
    "        (4, \"🔪 Segmentação Chunks\", \"04_SEGMENTACAO_CHUNKS.ipynb\"),\n",
    "        (5, \"🧠 Geração Embeddings\", \"05_GERACAO_EMBEDDINGS.ipynb\"),\n",
    "        (6, \"💾 Armazenamento Qdrant\", \"06_ARMAZENAMENTO_QDRANT.ipynb\"),\n",
    "        (7, \"📊 Validação Resultados\", \"07_VALIDACAO_RESULTADOS.ipynb\")\n",
    "    ]\n",
    "    \n",
    "    state = PipelineState()\n",
    "    \n",
    "    for stage_num, stage_name, notebook_file in stages:\n",
    "        print(f\"\\n{'='*20} ETAPA {stage_num} {'='*20}\")\n",
    "        print(f\"🎯 {stage_name}\")\n",
    "        print(f\"📓 Notebook: {notebook_file}\")\n",
    "        \n",
    "        # Verificar se notebook existe\n",
    "        if not Path(notebook_file).exists():\n",
    "            print(f\"❌ Notebook não encontrado: {notebook_file}\")\n",
    "            print(\"🛑 Pipeline interrompido\")\n",
    "            return False\n",
    "        \n",
    "        # Verificar dependências (etapas anteriores)\n",
    "        for prev_stage in range(1, stage_num):\n",
    "            if not state.is_stage_completed(prev_stage):\n",
    "                print(f\"❌ ERRO: Etapa {prev_stage} não foi concluída\")\n",
    "                print(f\"🛑 Pipeline interrompido na etapa {stage_num}\")\n",
    "                return False\n",
    "        \n",
    "        # Simular execução do notebook\n",
    "        print(\"🔄 Executando notebook...\")\n",
    "        print(\"🔄 Processando dados...\")\n",
    "        print(\"🔄 Salvando resultados...\")\n",
    "        \n",
    "        # Marcar etapa como concluída\n",
    "        state.mark_stage_completed(stage_num)\n",
    "        \n",
    "        print(f\"✅ Etapa {stage_num} concluída com sucesso!\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"🎉 PIPELINE COMPLETO EXECUTADO COM SUCESSO!\")\n",
    "    print(\"📊 Exibindo progresso final...\")\n",
    "    \n",
    "    show_pipeline_progress()\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Para executar pipeline completo, descomente a linha abaixo:\n",
    "# execute_full_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 Utilitários e Manutenção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_pipeline():\n",
    "    \"\"\"Reseta pipeline para nova execução\"\"\"\n",
    "    \n",
    "    print(\"🔄 RESETANDO PIPELINE\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    confirmation = input(\"⚠️ Tem certeza? Isso vai apagar todos os dados e checkpoints (y/N): \")\n",
    "    \n",
    "    if confirmation.lower() != 'y':\n",
    "        print(\"❌ Reset cancelado\")\n",
    "        return\n",
    "    \n",
    "    state = PipelineState()\n",
    "    \n",
    "    # Limpar checkpoints\n",
    "    for i in range(1, 8):\n",
    "        lock_file = state.checkpoints_dir / f\"stage_{i:02d}_completed.lock\"\n",
    "        if lock_file.exists():\n",
    "            lock_file.unlink()\n",
    "    \n",
    "    # Limpar metadata\n",
    "    for metadata_file in state.metadata_dir.glob(\"*.json\"):\n",
    "        metadata_file.unlink()\n",
    "    \n",
    "    # Limpar dados (opcional)\n",
    "    import shutil\n",
    "    for data_dir in [\"documents\", \"processed\", \"chunks\", \"embeddings\"]:\n",
    "        dir_path = state.base_dir / data_dir\n",
    "        if dir_path.exists():\n",
    "            shutil.rmtree(dir_path)\n",
    "            dir_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    print(\"✅ Pipeline resetado com sucesso!\")\n",
    "    print(\"📊 Status atual:\")\n",
    "    show_pipeline_progress()\n",
    "\n",
    "def show_pipeline_statistics():\n",
    "    \"\"\"Mostra estatísticas detalhadas do pipeline\"\"\"\n",
    "    \n",
    "    print(\"📊 ESTATÍSTICAS DO PIPELINE\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    state = PipelineState()\n",
    "    \n",
    "    # Estatísticas por etapa\n",
    "    for i in range(1, 8):\n",
    "        stage_name = state._get_stage_name(i)\n",
    "        completed = state.is_stage_completed(i)\n",
    "        \n",
    "        status = \"✅ Concluída\" if completed else \"⏳ Pendente\"\n",
    "        print(f\"Etapa {i} ({stage_name}): {status}\")\n",
    "        \n",
    "        # Verificar se há dados\n",
    "        try:\n",
    "            metadata_file = state.metadata_dir / f\"stage_{i:02d}_{stage_name}.json\"\n",
    "            if metadata_file.exists():\n",
    "                with open(metadata_file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    if 'statistics' in data:\n",
    "                        stats = data['statistics']\n",
    "                        for key, value in stats.items():\n",
    "                            print(f\"   {key}: {value}\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 40)\n",
    "\n",
    "# Funções de utilidade\n",
    "print(\"🛠️ UTILITÁRIOS DISPONÍVEIS:\")\n",
    "print(\"   reset_pipeline() - Reseta pipeline completo\")\n",
    "print(\"   show_pipeline_statistics() - Mostra estatísticas detalhadas\")\n",
    "print(\"   show_pipeline_progress() - Mostra progresso atual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📋 Comandos Rápidos\n",
    "\n",
    "### 🎯 **Para executar:**\n",
    "```python\n",
    "# Pipeline completo automático\n",
    "execute_full_pipeline()\n",
    "\n",
    "# Etapas individuais\n",
    "execute_stage_01()  # Fundação\n",
    "execute_stage_02()  # GitLab\n",
    "# ... etc\n",
    "\n",
    "# Utilitários\n",
    "show_pipeline_progress()      # Ver progresso\n",
    "show_pipeline_statistics()    # Ver estatísticas\n",
    "reset_pipeline()              # Resetar tudo\n",
    "```\n",
    "\n",
    "### 🔗 **Notebooks individuais:**\n",
    "- `01_FUNDACAO_PREPARACAO.ipynb` - Configuração e validação\n",
    "- `02_COLETA_GITLAB.ipynb` - Download de documentos\n",
    "- `03_PROCESSAMENTO_DOCLING.ipynb` - Extração de conteúdo\n",
    "- `04_SEGMENTACAO_CHUNKS.ipynb` - Segmentação de texto\n",
    "- `05_GERACAO_EMBEDDINGS.ipynb` - Geração de vetores\n",
    "- `06_ARMAZENAMENTO_QDRANT.ipynb` - Armazenamento vetorial\n",
    "- `07_VALIDACAO_RESULTADOS.ipynb` - Testes e validação\n",
    "\n",
    "---\n",
    "\n",
    "**🎉 Pipeline NIC ETL - Processamento Inteligente de Documentos**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}