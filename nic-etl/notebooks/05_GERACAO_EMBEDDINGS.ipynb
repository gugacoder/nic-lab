{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 🧠 ETAPA 5: GERAÇÃO DE EMBEDDINGS\n",
    "\n",
    "## 🎯 **O que esta etapa faz**\n",
    "Converte os chunks de texto em vetores de alta qualidade usando o modelo BAAI/bge-m3 para permitir busca semântica eficiente.\n",
    "\n",
    "## 🤔 **Por que esta etapa é necessária**\n",
    "Para realizar busca semântica, precisamos:\n",
    "- 🧠 **Converter texto em vetores** numéricos que capturem significado\n",
    "- 📊 **Usar modelo de qualidade** (BAAI/bge-m3) para embeddings precisos\n",
    "- 🎯 **Processar em lotes** para eficiência com grandes volumes\n",
    "- 📦 **Manter metadados** de origem e posição dos chunks\n",
    "\n",
    "## ⚙️ **Como funciona**\n",
    "1. **Carrega chunks** da etapa anterior\n",
    "2. **Inicializa modelo** BAAI/bge-m3 (1024 dimensões)\n",
    "3. **Processa em lotes** para otimizar uso de memória\n",
    "4. **Gera embeddings** normalizados para cada chunk\n",
    "5. **Combina com metadados** originais dos chunks\n",
    "6. **Salva embeddings** prontos para inserção no Qdrant\n",
    "\n",
    "## 📊 **Parâmetros que você pode ajustar**\n",
    "- `model_name`: Modelo de embeddings (padrão: \"BAAI/bge-m3\")\n",
    "- `batch_size`: Lote para processamento (padrão: 32)\n",
    "- `normalize_embeddings`: Normalizar vetores (padrão: True)\n",
    "- `device`: CPU ou GPU (automático)\n",
    "\n",
    "## 👁️ **O que esperar de saída**\n",
    "- 📁 **Pasta `embeddings/`** com vetores organizados\n",
    "- 📄 **Arquivos `*_embeddings.json`** com vetores e metadados\n",
    "- 📊 **Estatísticas** de geração por documento\n",
    "- 🎯 **Vetores de 1024 dimensões** prontos para Qdrant\n",
    "\n",
    "## ⚠️ **Pontos importantes**\n",
    "- **Requer Etapa 4** (Segmentação) concluída primeiro\n",
    "- **Processo intensivo** - pode demorar com muitos chunks\n",
    "- **Usa CPU** por padrão (GPU acelera se disponível)\n",
    "- **Vetores normalizados** para melhor qualidade de busca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 🛡️ Verificação de Dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🛡️ VERIFICAÇÃO AUTOMÁTICA DE DEPENDÊNCIAS\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Adicionar biblioteca ao path\n",
    "sys.path.insert(0, str(Path().parent / \"src\"))\n",
    "\n",
    "from pipeline_utils import (\n",
    "    PipelineState, \n",
    "    check_prerequisites, \n",
    "    show_pipeline_progress\n",
    ")\n",
    "\n",
    "print(\"🧠 ETAPA 5: GERAÇÃO DE EMBEDDINGS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"🕒 Iniciado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Verificar dependências\n",
    "CURRENT_STAGE = 5\n",
    "prerequisites_ok = check_prerequisites(CURRENT_STAGE)\n",
    "\n",
    "if not prerequisites_ok:\n",
    "    print(\"\\n❌ ERRO: Dependências não atendidas!\")\n",
    "    print(\"📋 Execute primeiro as etapas anteriores:\")\n",
    "    print(\"   1. 01_FUNDACAO_PREPARACAO.ipynb\")\n",
    "    print(\"   2. 02_COLETA_GITLAB.ipynb\")\n",
    "    print(\"   3. 03_PROCESSAMENTO_DOCLING.ipynb\")\n",
    "    print(\"   4. 04_SEGMENTACAO_CHUNKS.ipynb\")\n",
    "    \n",
    "    show_pipeline_progress()\n",
    "    raise RuntimeError(\"Dependências não atendidas - execute etapas anteriores primeiro\")\n",
    "\n",
    "print(\"\\n✅ Dependências verificadas - pode prosseguir\")\n",
    "print(\"📈 Progresso atual do pipeline:\")\n",
    "show_pipeline_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 📋 Configuração de Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📋 CONFIGURAÇÃO DOS PARÂMETROS DE EMBEDDINGS\n",
    "print(\"📋 Configurando parâmetros de geração de embeddings...\")\n",
    "\n",
    "# 🎯 PARÂMETROS AJUSTÁVEIS\n",
    "embedding_config = {\n",
    "    # Modelo\n",
    "    \"model_name\": \"BAAI/bge-m3\",\n",
    "    \"embedding_dimensions\": 1024,\n",
    "    \"normalize_embeddings\": True,\n",
    "    \n",
    "    # Processamento\n",
    "    \"batch_size\": 32,\n",
    "    \"max_length\": 8192,  # Limite do modelo\n",
    "    \"device\": \"auto\",     # CPU/GPU automático\n",
    "    \n",
    "    # Performance\n",
    "    \"show_progress\": True,\n",
    "    \"verbose_logging\": True,\n",
    "    \n",
    "    # Saída\n",
    "    \"output_dir\": \"../pipeline_data/embeddings\",\n",
    "    \"overwrite_existing\": True\n",
    "}\n",
    "\n",
    "print(\"\\n📊 Parâmetros de embeddings configurados:\")\n",
    "print(f\"   🤖 Modelo: {embedding_config['model_name']}\")\n",
    "print(f\"   📊 Dimensões: {embedding_config['embedding_dimensions']}\")\n",
    "print(f\"   📦 Batch size: {embedding_config['batch_size']}\")\n",
    "print(f\"   📏 Comprimento máximo: {embedding_config['max_length']} tokens\")\n",
    "print(f\"   🎛️ Normalização: {embedding_config['normalize_embeddings']}\")\n",
    "print(f\"   💻 Device: {embedding_config['device']}\")\n",
    "print(f\"   📁 Saída: {embedding_config['output_dir']}\")\n",
    "\n",
    "# Preparar diretório de saída\n",
    "from pipeline_utils import ensure_directory\n",
    "ensure_directory(embedding_config[\"output_dir\"])\n",
    "\n",
    "print(\"\\n✅ Configuração de embeddings pronta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 📄 Carregamento dos Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📄 CARREGAMENTO DOS CHUNKS DA ETAPA ANTERIOR\n",
    "print(\"📄 Carregando chunks da etapa anterior...\")\n",
    "\n",
    "# Carregar dados da etapa 4 (Chunking)\n",
    "state = PipelineState()\n",
    "try:\n",
    "    chunking_data = state.load_stage_data(4)\n",
    "    print(\"✅ Dados carregados da Etapa 4 (Chunks)\")\n",
    "    \n",
    "    chunk_files = chunking_data[\"next_stage_instructions\"][\"chunk_files_to_embed\"]\n",
    "    chunks_directory = chunking_data[\"next_stage_instructions\"][\"chunks_directory\"]\n",
    "    total_chunks = chunking_data[\"next_stage_instructions\"][\"total_chunks_to_process\"]\n",
    "    \n",
    "    print(f\"   📄 Arquivos de chunks: {len(chunk_files)}\")\n",
    "    print(f\"   🔪 Total de chunks: {total_chunks:,}\")\n",
    "    print(f\"   📁 Diretório origem: {chunks_directory}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Erro ao carregar dados: {e}\")\n",
    "    raise\n",
    "\n",
    "# Verificar se arquivos de chunks existem\n",
    "available_chunk_files = []\n",
    "total_chunks_found = 0\n",
    "\n",
    "for chunk_file_path in chunk_files:\n",
    "    file_path = Path(chunk_file_path)\n",
    "    if file_path.exists():\n",
    "        # Contar chunks no arquivo\n",
    "        try:\n",
    "            import json\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                chunk_data = json.load(f)\n",
    "                chunks_count = len(chunk_data.get(\"chunks\", []))\n",
    "                total_chunks_found += chunks_count\n",
    "                \n",
    "            available_chunk_files.append(chunk_file_path)\n",
    "            print(f\"   ✅ {file_path.name} ({chunks_count:,} chunks)\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Erro ao ler {file_path.name}: {e}\")\n",
    "    else:\n",
    "        print(f\"   ❌ {file_path.name} (não encontrado)\")\n",
    "\n",
    "if not available_chunk_files:\n",
    "    print(\"\\n❌ Nenhum arquivo de chunk disponível para embeddings\")\n",
    "    raise ValueError(\"Nenhum arquivo de chunk para processar\")\n",
    "\n",
    "print(f\"\\n📊 Arquivos prontos para embeddings: {len(available_chunk_files)}\")\n",
    "print(f\"🔪 Total de chunks encontrados: {total_chunks_found:,}\")\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 🧠 Geração de Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧠 EXECUÇÃO DA GERAÇÃO DE EMBEDDINGS\n",
    "print(\"🧠 Iniciando geração de embeddings...\")\n",
    "\n",
    "from embedding_utils import batch_process_chunks_to_embeddings\n",
    "from pipeline_utils import format_file_size\n",
    "import json\n",
    "\n",
    "print(f\"\\n🚀 Processando {len(available_chunk_files)} arquivos de chunks...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Executar geração de embeddings em lote\n",
    "start_time = datetime.now()\n",
    "\n",
    "embedding_results = batch_process_chunks_to_embeddings(\n",
    "    chunks_files=available_chunk_files,\n",
    "    output_dir=embedding_config[\"output_dir\"],\n",
    "    model_name=embedding_config[\"model_name\"]\n",
    ")\n",
    "\n",
    "end_time = datetime.now()\n",
    "embedding_duration = (end_time - start_time).total_seconds()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"📊 RESULTADO DA GERAÇÃO DE EMBEDDINGS:\")\n",
    "\n",
    "# Contar sucessos e falhas\n",
    "successful_embeddings = [r for r in embedding_results if r[\"status\"] == \"success\"]\n",
    "failed_embeddings = [r for r in embedding_results if r[\"status\"] == \"failed\"]\n",
    "\n",
    "total_embeddings = sum(r[\"embedding_count\"] for r in successful_embeddings)\n",
    "total_vectors_size_mb = (total_embeddings * embedding_config[\"embedding_dimensions\"] * 4) / (1024*1024)  # float32\n",
    "\n",
    "print(f\"   📄 Arquivos processados: {len(embedding_results)}\")\n",
    "print(f\"   ✅ Sucessos: {len(successful_embeddings)}\")\n",
    "print(f\"   ❌ Falhas: {len(failed_embeddings)}\")\n",
    "print(f\"   🧠 Total de embeddings: {total_embeddings:,}\")\n",
    "print(f\"   📊 Dimensões: {embedding_config['embedding_dimensions']}\")\n",
    "print(f\"   💾 Tamanho total: {total_vectors_size_mb:.1f} MB\")\n",
    "print(f\"   ⏱️ Tempo total: {embedding_duration:.1f} segundos\")\n",
    "\n",
    "if successful_embeddings:\n",
    "    avg_embeddings_per_file = total_embeddings / len(successful_embeddings)\n",
    "    avg_processing_speed = total_embeddings / embedding_duration if embedding_duration > 0 else 0\n",
    "    print(f\"   📈 Média: {avg_embeddings_per_file:.1f} embeddings por arquivo\")\n",
    "    print(f\"   ⚡ Velocidade: {avg_processing_speed:.1f} embeddings/segundo\")\n",
    "\n",
    "# Mostrar resultados de sucesso\n",
    "if successful_embeddings:\n",
    "    print(\"\\n📁 Arquivos processados com sucesso:\")\n",
    "    for result in successful_embeddings[:10]:  # Mostrar apenas os primeiros 10\n",
    "        filename = Path(result[\"source_chunks_file\"]).name\n",
    "        embeddings = result[\"embedding_count\"]\n",
    "        model = result[\"model_name\"]\n",
    "        print(f\"   ✅ {filename}: {embeddings:,} embeddings ({model})\")\n",
    "    \n",
    "    if len(successful_embeddings) > 10:\n",
    "        remaining = len(successful_embeddings) - 10\n",
    "        print(f\"   ... e mais {remaining} arquivos\")\n",
    "\n",
    "# Mostrar falhas se houver\n",
    "if failed_embeddings:\n",
    "    print(f\"\\n⚠️ Arquivos com problemas ({len(failed_embeddings)}):\")\n",
    "    for result in failed_embeddings[:5]:  # Mostrar apenas os primeiros 5\n",
    "        filename = Path(result[\"source_chunks_file\"]).name\n",
    "        error = result[\"error\"]\n",
    "        print(f\"   ❌ {filename}: {error}\")\n",
    "    \n",
    "    if len(failed_embeddings) > 5:\n",
    "        remaining = len(failed_embeddings) - 5\n",
    "        print(f\"   ... e mais {remaining} erros\")\n",
    "\n",
    "print(\"\\n✅ Geração de embeddings concluída!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 📊 Validação e Qualidade dos Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 VALIDAÇÃO E ANÁLISE DE QUALIDADE DOS EMBEDDINGS\n",
    "print(\"📊 Validando qualidade dos embeddings...\")\n",
    "\n",
    "from embedding_utils import validate_embeddings\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Validar embeddings gerados\n",
    "validation_result = validate_embeddings(embedding_config[\"output_dir\"])\n",
    "\n",
    "if validation_result[\"valid\"]:\n",
    "    print(\"\\n✅ Validação bem-sucedida\")\n",
    "    print(f\"   📄 Arquivos de embeddings: {validation_result['embedding_files_count']}\")\n",
    "    print(f\"   🧠 Total de embeddings: {validation_result['total_embeddings']:,}\")\n",
    "    print(f\"   📊 Dimensões médias: {validation_result['avg_dimensions']:.0f}\")\n",
    "    print(f\"   🤖 Modelos usados: {', '.join(validation_result['models_used'])}\")\n",
    "else:\n",
    "    print(f\"\\n❌ Problema na validação: {validation_result.get('error', 'Erro desconhecido')}\")\n",
    "\n",
    "# Análise detalhada de qualidade\n",
    "embeddings_dir = Path(embedding_config[\"output_dir\"])\n",
    "embedding_files = list(embeddings_dir.glob(\"*_embeddings.json\"))\n",
    "\n",
    "quality_stats = {\n",
    "    \"total_embeddings\": 0,\n",
    "    \"total_dimensions\": 0,\n",
    "    \"models_used\": set(),\n",
    "    \"avg_vector_magnitude\": [],\n",
    "    \"empty_embeddings\": 0,\n",
    "    \"dimension_consistency\": True\n",
    "}\n",
    "\n",
    "print(f\"\\n📈 Análise detalhada de {len(embedding_files)} arquivos de embeddings:\")\n",
    "\n",
    "expected_dimensions = embedding_config[\"embedding_dimensions\"]\n",
    "\n",
    "for embedding_file in embedding_files:\n",
    "    try:\n",
    "        with open(embedding_file, 'r', encoding='utf-8') as f:\n",
    "            embedding_data = json.load(f)\n",
    "        \n",
    "        chunks = embedding_data.get(\"chunks_with_embeddings\", [])\n",
    "        \n",
    "        for chunk in chunks:\n",
    "            embedding = chunk.get(\"embedding\", [])\n",
    "            model_name = chunk.get(\"embedding_model\", \"unknown\")\n",
    "            dimensions = chunk.get(\"embedding_dimensions\", 0)\n",
    "            \n",
    "            quality_stats[\"total_embeddings\"] += 1\n",
    "            quality_stats[\"total_dimensions\"] += dimensions\n",
    "            quality_stats[\"models_used\"].add(model_name)\n",
    "            \n",
    "            # Verificar dimensões\n",
    "            if dimensions != expected_dimensions:\n",
    "                quality_stats[\"dimension_consistency\"] = False\n",
    "            \n",
    "            # Verificar embeddings vazios\n",
    "            if not embedding or len(embedding) == 0:\n",
    "                quality_stats[\"empty_embeddings\"] += 1\n",
    "            else:\n",
    "                # Calcular magnitude do vetor\n",
    "                try:\n",
    "                    vector_magnitude = np.linalg.norm(embedding)\n",
    "                    quality_stats[\"avg_vector_magnitude\"].append(vector_magnitude)\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ Erro ao analisar {embedding_file.name}: {e}\")\n",
    "\n",
    "# Estatísticas de qualidade\n",
    "if quality_stats[\"total_embeddings\"] > 0:\n",
    "    avg_dimensions = quality_stats[\"total_dimensions\"] / quality_stats[\"total_embeddings\"]\n",
    "    avg_magnitude = np.mean(quality_stats[\"avg_vector_magnitude\"]) if quality_stats[\"avg_vector_magnitude\"] else 0\n",
    "    \n",
    "    print(f\"\\n📏 Estatísticas de qualidade:\")\n",
    "    print(f\"   📊 Embeddings totais: {quality_stats['total_embeddings']:,}\")\n",
    "    print(f\"   📐 Dimensões médias: {avg_dimensions:.0f}\")\n",
    "    print(f\"   📊 Dimensões esperadas: {expected_dimensions}\")\n",
    "    print(f\"   ✅ Consistência dimensional: {quality_stats['dimension_consistency']}\")\n",
    "    print(f\"   📈 Magnitude média dos vetores: {avg_magnitude:.3f}\")\n",
    "    \n",
    "    if quality_stats[\"empty_embeddings\"] > 0:\n",
    "        print(f\"\\n⚠️ Problemas encontrados:\")\n",
    "        print(f\"   Embeddings vazios: {quality_stats['empty_embeddings']}\")\n",
    "    \n",
    "    print(f\"\\n🤖 Modelos utilizados:\")\n",
    "    for model in quality_stats[\"models_used\"]:\n",
    "        print(f\"   - {model}\")\n",
    "\n",
    "# Preparar lista de arquivos de embeddings para próxima etapa\n",
    "embedding_files_info = []\n",
    "for result in successful_embeddings:\n",
    "    embedding_files_info.append({\n",
    "        \"source_chunks_file\": result[\"source_chunks_file\"],\n",
    "        \"embeddings_file\": result[\"embeddings_file\"],\n",
    "        \"embedding_count\": result[\"embedding_count\"],\n",
    "        \"model_name\": result[\"model_name\"]\n",
    "    })\n",
    "\n",
    "print(f\"\\n📋 Arquivos de embeddings preparados para próxima etapa: {len(embedding_files_info)}\")\n",
    "print(\"✅ Validação concluída!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 💾 Salvamento dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 💾 SALVAMENTO DOS RESULTADOS PARA PRÓXIMA ETAPA\n",
    "print(\"💾 Salvando resultados da geração de embeddings...\")\n",
    "\n",
    "from pipeline_utils import get_timestamp\n",
    "\n",
    "# Preparar dados de saída para próxima etapa\n",
    "stage_output = {\n",
    "    \"stage_info\": {\n",
    "        \"stage_number\": 5,\n",
    "        \"stage_name\": \"embeddings\",\n",
    "        \"completed_at\": get_timestamp(),\n",
    "        \"status\": \"success\" if len(successful_embeddings) > 0 else \"completed_with_warnings\",\n",
    "        \"embedding_duration_seconds\": embedding_duration\n",
    "    },\n",
    "    \n",
    "    \"embedding_config\": embedding_config,\n",
    "    \n",
    "    \"input_files\": {\n",
    "        \"total_chunk_files\": len(chunk_files),\n",
    "        \"available_files\": len(available_chunk_files),\n",
    "        \"processed_files\": len(embedding_results)\n",
    "    },\n",
    "    \n",
    "    \"embedding_files\": embedding_files_info,\n",
    "    \n",
    "    \"embedding_results\": {\n",
    "        \"successful_files\": len(successful_embeddings),\n",
    "        \"failed_files\": len(failed_embeddings),\n",
    "        \"total_embeddings_created\": total_embeddings,\n",
    "        \"total_vector_size_mb\": total_vectors_size_mb\n",
    "    },\n",
    "    \n",
    "    \"quality_analysis\": {\n",
    "        \"total_embeddings\": quality_stats[\"total_embeddings\"],\n",
    "        \"avg_dimensions\": quality_stats[\"total_dimensions\"] / quality_stats[\"total_embeddings\"] if quality_stats[\"total_embeddings\"] > 0 else 0,\n",
    "        \"expected_dimensions\": expected_dimensions,\n",
    "        \"dimension_consistency\": quality_stats[\"dimension_consistency\"],\n",
    "        \"empty_embeddings\": quality_stats[\"empty_embeddings\"],\n",
    "        \"avg_vector_magnitude\": np.mean(quality_stats[\"avg_vector_magnitude\"]) if quality_stats[\"avg_vector_magnitude\"] else 0,\n",
    "        \"models_used\": list(quality_stats[\"models_used\"])\n",
    "    },\n",
    "    \n",
    "    \"statistics\": {\n",
    "        \"files_processed\": len(successful_embeddings),\n",
    "        \"total_embeddings\": total_embeddings,\n",
    "        \"avg_embeddings_per_file\": total_embeddings / len(successful_embeddings) if successful_embeddings else 0,\n",
    "        \"processing_time_seconds\": embedding_duration,\n",
    "        \"processing_speed_embeddings_per_sec\": total_embeddings / embedding_duration if embedding_duration > 0 else 0,\n",
    "        \"total_vector_size_mb\": total_vectors_size_mb,\n",
    "        \"embedding_files_generated\": len(embedding_files)\n",
    "    },\n",
    "    \n",
    "    \"errors\": [\n",
    "        {\n",
    "            \"source_chunks_file\": result[\"source_chunks_file\"],\n",
    "            \"error\": result[\"error\"]\n",
    "        }\n",
    "        for result in failed_embeddings\n",
    "    ],\n",
    "    \n",
    "    \"next_stage_instructions\": {\n",
    "        \"embeddings_directory\": embedding_config[\"output_dir\"],\n",
    "        \"embedding_files_to_store\": [info[\"embeddings_file\"] for info in embedding_files_info],\n",
    "        \"total_embeddings_to_store\": total_embeddings,\n",
    "        \"vector_dimensions\": expected_dimensions,\n",
    "        \"recommended_batch_size\": 100,\n",
    "        \"qdrant_collection_config\": {\n",
    "            \"vector_size\": expected_dimensions,\n",
    "            \"distance_metric\": \"Cosine\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Salvar usando PipelineState\n",
    "state = PipelineState()\n",
    "state.save_stage_data(5, stage_output)\n",
    "\n",
    "# Marcar etapa como concluída\n",
    "state.mark_stage_completed(5)\n",
    "\n",
    "print(f\"✅ Resultados salvos: {state.metadata_dir / 'stage_05_embeddings.json'}\")\n",
    "print(f\"✅ Checkpoint criado: {state.checkpoints_dir / 'stage_05_completed.lock'}\")\n",
    "\n",
    "# Salvar relatório detalhado de embeddings\n",
    "embedding_report_path = Path(embedding_config[\"output_dir\"]) / \"embedding_report.json\"\n",
    "with open(embedding_report_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump({\n",
    "        \"timestamp\": get_timestamp(),\n",
    "        \"config\": embedding_config,\n",
    "        \"results\": embedding_results,\n",
    "        \"quality_stats\": {\n",
    "            k: (list(v) if isinstance(v, set) else float(v) if isinstance(v, np.float64) else v) \n",
    "            for k, v in quality_stats.items()\n",
    "        },\n",
    "        \"validation\": validation_result\n",
    "    }, f, indent=2, ensure_ascii=False, default=str)\n",
    "\n",
    "print(f\"📝 Relatório detalhado salvo: {embedding_report_path}\")\n",
    "\n",
    "# Exibir resumo final\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🎉 ETAPA 5 CONCLUÍDA COM SUCESSO!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"📊 Resumo da Geração de Embeddings:\")\n",
    "print(f\"   📄 Arquivos processados: {len(successful_embeddings)}/{len(available_chunk_files)}\")\n",
    "print(f\"   🧠 Embeddings criados: {total_embeddings:,}\")\n",
    "print(f\"   📊 Dimensões: {expected_dimensions}\")\n",
    "print(f\"   🤖 Modelo: {embedding_config['model_name']}\")\n",
    "print(f\"   💾 Tamanho total: {total_vectors_size_mb:.1f} MB\")\n",
    "print(f\"   ⏱️ Tempo total: {embedding_duration:.1f} segundos\")\n",
    "print(f\"   📍 Localização: {embedding_config['output_dir']}\")\n",
    "\n",
    "if failed_embeddings:\n",
    "    print(f\"   ⚠️ Avisos: {len(failed_embeddings)} arquivos falharam\")\n",
    "else:\n",
    "    print(f\"   ✅ Status: Todos os arquivos processados com sucesso\")\n",
    "\n",
    "print(f\"\\n🚀 Pronto para próxima etapa: 06_ARMAZENAMENTO_QDRANT.ipynb\")\n",
    "print(f\"📋 {total_embeddings:,} embeddings prontos para armazenamento\")\n",
    "\n",
    "# Exibir progresso do pipeline\n",
    "print(\"\\n📈 Progresso do Pipeline:\")\n",
    "show_pipeline_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ✅ **Etapa 5 Concluída!**\n",
    "\n",
    "### 🎯 **O que foi feito:**\n",
    "- ✅ Chunks convertidos em embeddings de alta qualidade\n",
    "- ✅ Modelo BAAI/bge-m3 carregado e utilizado\n",
    "- ✅ Processamento em lotes para eficiência\n",
    "- ✅ Vetores normalizados (1024 dimensões)\n",
    "- ✅ Qualidade validada e estatísticas coletadas\n",
    "- ✅ Embeddings organizados e catalogados\n",
    "\n",
    "### 🚀 **Próxima etapa:**\n",
    "**`06_ARMAZENAMENTO_QDRANT.ipynb`** - Inserção dos vetores no Qdrant\n",
    "\n",
    "### 📊 **Arquivos gerados:**\n",
    "- `pipeline_data/embeddings/` - Embeddings organizados por documento\n",
    "- `pipeline_data/embeddings/*_embeddings.json` - Vetores com metadados completos\n",
    "- `pipeline_data/metadata/stage_05_embeddings.json` - Estatísticas e configuração\n",
    "- `pipeline_data/embeddings/embedding_report.json` - Relatório detalhado de qualidade\n",
    "- `pipeline_data/checkpoints/stage_05_completed.lock` - Checkpoint de conclusão\n",
    "\n",
    "### 📋 **Dados para próxima etapa:**\n",
    "- **Embeddings vetorizados:** Prontos para inserção no Qdrant\n",
    "- **Metadados preservados:** Origem, chunks, posições\n",
    "- **Qualidade validada:** Dimensões corretas, vetores normalizados\n",
    "\n",
    "### 🔧 **Para executar próxima etapa:**\n",
    "1. Abra o notebook `06_ARMAZENAMENTO_QDRANT.ipynb`\n",
    "2. Execute as células em sequência\n",
    "3. Ou use o `00_PIPELINE_MASTER.ipynb` para execução automática\n",
    "\n",
    "---\n",
    "\n",
    "**🧠 Embeddings de alta qualidade gerados! Prontos para busca semântica.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}