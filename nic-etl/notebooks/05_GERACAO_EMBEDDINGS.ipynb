{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# ğŸ§  ETAPA 5: GERAÃ‡ÃƒO DE EMBEDDINGS\n",
    "\n",
    "## ğŸ¯ **O que esta etapa faz**\n",
    "Converte os chunks de texto em vetores de alta qualidade usando o modelo BAAI/bge-m3 para permitir busca semÃ¢ntica eficiente.\n",
    "\n",
    "## ğŸ¤” **Por que esta etapa Ã© necessÃ¡ria**\n",
    "Para realizar busca semÃ¢ntica, precisamos:\n",
    "- ğŸ§  **Converter texto em vetores** numÃ©ricos que capturem significado\n",
    "- ğŸ“Š **Usar modelo de qualidade** (BAAI/bge-m3) para embeddings precisos\n",
    "- ğŸ¯ **Processar em lotes** para eficiÃªncia com grandes volumes\n",
    "- ğŸ“¦ **Manter metadados** de origem e posiÃ§Ã£o dos chunks\n",
    "\n",
    "## âš™ï¸ **Como funciona**\n",
    "1. **Carrega chunks** da etapa anterior\n",
    "2. **Inicializa modelo** BAAI/bge-m3 (1024 dimensÃµes)\n",
    "3. **Processa em lotes** para otimizar uso de memÃ³ria\n",
    "4. **Gera embeddings** normalizados para cada chunk\n",
    "5. **Combina com metadados** originais dos chunks\n",
    "6. **Salva embeddings** prontos para inserÃ§Ã£o no Qdrant\n",
    "\n",
    "## ğŸ“Š **ParÃ¢metros que vocÃª pode ajustar**\n",
    "- `model_name`: Modelo de embeddings (padrÃ£o: \"BAAI/bge-m3\")\n",
    "- `batch_size`: Lote para processamento (padrÃ£o: 32)\n",
    "- `normalize_embeddings`: Normalizar vetores (padrÃ£o: True)\n",
    "- `device`: CPU ou GPU (automÃ¡tico)\n",
    "\n",
    "## ğŸ‘ï¸ **O que esperar de saÃ­da**\n",
    "- ğŸ“ **Pasta `embeddings/`** com vetores organizados\n",
    "- ğŸ“„ **Arquivos `*_embeddings.json`** com vetores e metadados\n",
    "- ğŸ“Š **EstatÃ­sticas** de geraÃ§Ã£o por documento\n",
    "- ğŸ¯ **Vetores de 1024 dimensÃµes** prontos para Qdrant\n",
    "\n",
    "## âš ï¸ **Pontos importantes**\n",
    "- **Requer Etapa 4** (SegmentaÃ§Ã£o) concluÃ­da primeiro\n",
    "- **Processo intensivo** - pode demorar com muitos chunks\n",
    "- **Usa CPU** por padrÃ£o (GPU acelera se disponÃ­vel)\n",
    "- **Vetores normalizados** para melhor qualidade de busca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## ğŸ›¡ï¸ VerificaÃ§Ã£o de DependÃªncias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ›¡ï¸ VERIFICAÃ‡ÃƒO AUTOMÃTICA DE DEPENDÃŠNCIAS\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Adicionar biblioteca ao path\n",
    "sys.path.insert(0, str(Path().parent / \"src\"))\n",
    "\n",
    "from pipeline_utils import (\n",
    "    PipelineState, \n",
    "    check_prerequisites, \n",
    "    show_pipeline_progress\n",
    ")\n",
    "\n",
    "print(\"ğŸ§  ETAPA 5: GERAÃ‡ÃƒO DE EMBEDDINGS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ğŸ•’ Iniciado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Verificar dependÃªncias\n",
    "CURRENT_STAGE = 5\n",
    "prerequisites_ok = check_prerequisites(CURRENT_STAGE)\n",
    "\n",
    "if not prerequisites_ok:\n",
    "    print(\"\\nâŒ ERRO: DependÃªncias nÃ£o atendidas!\")\n",
    "    print(\"ğŸ“‹ Execute primeiro as etapas anteriores:\")\n",
    "    print(\"   1. 01_FUNDACAO_PREPARACAO.ipynb\")\n",
    "    print(\"   2. 02_COLETA_GITLAB.ipynb\")\n",
    "    print(\"   3. 03_PROCESSAMENTO_DOCLING.ipynb\")\n",
    "    print(\"   4. 04_SEGMENTACAO_CHUNKS.ipynb\")\n",
    "    \n",
    "    show_pipeline_progress()\n",
    "    raise RuntimeError(\"DependÃªncias nÃ£o atendidas - execute etapas anteriores primeiro\")\n",
    "\n",
    "print(\"\\nâœ… DependÃªncias verificadas - pode prosseguir\")\n",
    "print(\"ğŸ“ˆ Progresso atual do pipeline:\")\n",
    "show_pipeline_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## ğŸ“‹ ConfiguraÃ§Ã£o de Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“‹ CONFIGURAÃ‡ÃƒO DOS PARÃ‚METROS DE EMBEDDINGS\n",
    "print(\"ğŸ“‹ Configurando parÃ¢metros de geraÃ§Ã£o de embeddings...\")\n",
    "\n",
    "# ğŸ¯ PARÃ‚METROS AJUSTÃVEIS\n",
    "embedding_config = {\n",
    "    # Modelo\n",
    "    \"model_name\": \"BAAI/bge-m3\",\n",
    "    \"embedding_dimensions\": 1024,\n",
    "    \"normalize_embeddings\": True,\n",
    "    \n",
    "    # Processamento\n",
    "    \"batch_size\": 32,\n",
    "    \"max_length\": 8192,  # Limite do modelo\n",
    "    \"device\": \"auto\",     # CPU/GPU automÃ¡tico\n",
    "    \n",
    "    # Performance\n",
    "    \"show_progress\": True,\n",
    "    \"verbose_logging\": True,\n",
    "    \n",
    "    # SaÃ­da\n",
    "    \"output_dir\": \"../pipeline_data/embeddings\",\n",
    "    \"overwrite_existing\": True\n",
    "}\n",
    "\n",
    "print(\"\\nğŸ“Š ParÃ¢metros de embeddings configurados:\")\n",
    "print(f\"   ğŸ¤– Modelo: {embedding_config['model_name']}\")\n",
    "print(f\"   ğŸ“Š DimensÃµes: {embedding_config['embedding_dimensions']}\")\n",
    "print(f\"   ğŸ“¦ Batch size: {embedding_config['batch_size']}\")\n",
    "print(f\"   ğŸ“ Comprimento mÃ¡ximo: {embedding_config['max_length']} tokens\")\n",
    "print(f\"   ğŸ›ï¸ NormalizaÃ§Ã£o: {embedding_config['normalize_embeddings']}\")\n",
    "print(f\"   ğŸ’» Device: {embedding_config['device']}\")\n",
    "print(f\"   ğŸ“ SaÃ­da: {embedding_config['output_dir']}\")\n",
    "\n",
    "# Preparar diretÃ³rio de saÃ­da\n",
    "from pipeline_utils import ensure_directory\n",
    "ensure_directory(embedding_config[\"output_dir\"])\n",
    "\n",
    "print(\"\\nâœ… ConfiguraÃ§Ã£o de embeddings pronta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## ğŸ“„ Carregamento dos Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“„ CARREGAMENTO DOS CHUNKS DA ETAPA ANTERIOR\n",
    "print(\"ğŸ“„ Carregando chunks da etapa anterior...\")\n",
    "\n",
    "# Carregar dados da etapa 4 (Chunking)\n",
    "state = PipelineState()\n",
    "try:\n",
    "    chunking_data = state.load_stage_data(4)\n",
    "    print(\"âœ… Dados carregados da Etapa 4 (Chunks)\")\n",
    "    \n",
    "    chunk_files = chunking_data[\"next_stage_instructions\"][\"chunk_files_to_embed\"]\n",
    "    chunks_directory = chunking_data[\"next_stage_instructions\"][\"chunks_directory\"]\n",
    "    total_chunks = chunking_data[\"next_stage_instructions\"][\"total_chunks_to_process\"]\n",
    "    \n",
    "    print(f\"   ğŸ“„ Arquivos de chunks: {len(chunk_files)}\")\n",
    "    print(f\"   ğŸ”ª Total de chunks: {total_chunks:,}\")\n",
    "    print(f\"   ğŸ“ DiretÃ³rio origem: {chunks_directory}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erro ao carregar dados: {e}\")\n",
    "    raise\n",
    "\n",
    "# Verificar se arquivos de chunks existem\n",
    "available_chunk_files = []\n",
    "total_chunks_found = 0\n",
    "\n",
    "for chunk_file_path in chunk_files:\n",
    "    file_path = Path(chunk_file_path)\n",
    "    if file_path.exists():\n",
    "        # Contar chunks no arquivo\n",
    "        try:\n",
    "            import json\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                chunk_data = json.load(f)\n",
    "                chunks_count = len(chunk_data.get(\"chunks\", []))\n",
    "                total_chunks_found += chunks_count\n",
    "                \n",
    "            available_chunk_files.append(chunk_file_path)\n",
    "            print(f\"   âœ… {file_path.name} ({chunks_count:,} chunks)\")\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Erro ao ler {file_path.name}: {e}\")\n",
    "    else:\n",
    "        print(f\"   âŒ {file_path.name} (nÃ£o encontrado)\")\n",
    "\n",
    "if not available_chunk_files:\n",
    "    print(\"\\nâŒ Nenhum arquivo de chunk disponÃ­vel para embeddings\")\n",
    "    raise ValueError(\"Nenhum arquivo de chunk para processar\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Arquivos prontos para embeddings: {len(available_chunk_files)}\")\n",
    "print(f\"ğŸ”ª Total de chunks encontrados: {total_chunks_found:,}\")\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## ğŸ§  GeraÃ§Ã£o de Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§  EXECUÃ‡ÃƒO DA GERAÃ‡ÃƒO DE EMBEDDINGS\n",
    "print(\"ğŸ§  Iniciando geraÃ§Ã£o de embeddings...\")\n",
    "\n",
    "from embedding_utils import batch_process_chunks_to_embeddings\n",
    "from pipeline_utils import format_file_size\n",
    "import json\n",
    "\n",
    "print(f\"\\nğŸš€ Processando {len(available_chunk_files)} arquivos de chunks...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Executar geraÃ§Ã£o de embeddings em lote\n",
    "start_time = datetime.now()\n",
    "\n",
    "embedding_results = batch_process_chunks_to_embeddings(\n",
    "    chunks_files=available_chunk_files,\n",
    "    output_dir=embedding_config[\"output_dir\"],\n",
    "    model_name=embedding_config[\"model_name\"]\n",
    ")\n",
    "\n",
    "end_time = datetime.now()\n",
    "embedding_duration = (end_time - start_time).total_seconds()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ“Š RESULTADO DA GERAÃ‡ÃƒO DE EMBEDDINGS:\")\n",
    "\n",
    "# Contar sucessos e falhas\n",
    "successful_embeddings = [r for r in embedding_results if r[\"status\"] == \"success\"]\n",
    "failed_embeddings = [r for r in embedding_results if r[\"status\"] == \"failed\"]\n",
    "\n",
    "total_embeddings = sum(r[\"embedding_count\"] for r in successful_embeddings)\n",
    "total_vectors_size_mb = (total_embeddings * embedding_config[\"embedding_dimensions\"] * 4) / (1024*1024)  # float32\n",
    "\n",
    "print(f\"   ğŸ“„ Arquivos processados: {len(embedding_results)}\")\n",
    "print(f\"   âœ… Sucessos: {len(successful_embeddings)}\")\n",
    "print(f\"   âŒ Falhas: {len(failed_embeddings)}\")\n",
    "print(f\"   ğŸ§  Total de embeddings: {total_embeddings:,}\")\n",
    "print(f\"   ğŸ“Š DimensÃµes: {embedding_config['embedding_dimensions']}\")\n",
    "print(f\"   ğŸ’¾ Tamanho total: {total_vectors_size_mb:.1f} MB\")\n",
    "print(f\"   â±ï¸ Tempo total: {embedding_duration:.1f} segundos\")\n",
    "\n",
    "if successful_embeddings:\n",
    "    avg_embeddings_per_file = total_embeddings / len(successful_embeddings)\n",
    "    avg_processing_speed = total_embeddings / embedding_duration if embedding_duration > 0 else 0\n",
    "    print(f\"   ğŸ“ˆ MÃ©dia: {avg_embeddings_per_file:.1f} embeddings por arquivo\")\n",
    "    print(f\"   âš¡ Velocidade: {avg_processing_speed:.1f} embeddings/segundo\")\n",
    "\n",
    "# Mostrar resultados de sucesso\n",
    "if successful_embeddings:\n",
    "    print(\"\\nğŸ“ Arquivos processados com sucesso:\")\n",
    "    for result in successful_embeddings[:10]:  # Mostrar apenas os primeiros 10\n",
    "        filename = Path(result[\"source_chunks_file\"]).name\n",
    "        embeddings = result[\"embedding_count\"]\n",
    "        model = result[\"model_name\"]\n",
    "        print(f\"   âœ… {filename}: {embeddings:,} embeddings ({model})\")\n",
    "    \n",
    "    if len(successful_embeddings) > 10:\n",
    "        remaining = len(successful_embeddings) - 10\n",
    "        print(f\"   ... e mais {remaining} arquivos\")\n",
    "\n",
    "# Mostrar falhas se houver\n",
    "if failed_embeddings:\n",
    "    print(f\"\\nâš ï¸ Arquivos com problemas ({len(failed_embeddings)}):\")\n",
    "    for result in failed_embeddings[:5]:  # Mostrar apenas os primeiros 5\n",
    "        filename = Path(result[\"source_chunks_file\"]).name\n",
    "        error = result[\"error\"]\n",
    "        print(f\"   âŒ {filename}: {error}\")\n",
    "    \n",
    "    if len(failed_embeddings) > 5:\n",
    "        remaining = len(failed_embeddings) - 5\n",
    "        print(f\"   ... e mais {remaining} erros\")\n",
    "\n",
    "print(\"\\nâœ… GeraÃ§Ã£o de embeddings concluÃ­da!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## ğŸ“Š ValidaÃ§Ã£o e Qualidade dos Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š VALIDAÃ‡ÃƒO E ANÃLISE DE QUALIDADE DOS EMBEDDINGS\n",
    "print(\"ğŸ“Š Validando qualidade dos embeddings...\")\n",
    "\n",
    "from embedding_utils import validate_embeddings\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Validar embeddings gerados\n",
    "validation_result = validate_embeddings(embedding_config[\"output_dir\"])\n",
    "\n",
    "if validation_result[\"valid\"]:\n",
    "    print(\"\\nâœ… ValidaÃ§Ã£o bem-sucedida\")\n",
    "    print(f\"   ğŸ“„ Arquivos de embeddings: {validation_result['embedding_files_count']}\")\n",
    "    print(f\"   ğŸ§  Total de embeddings: {validation_result['total_embeddings']:,}\")\n",
    "    print(f\"   ğŸ“Š DimensÃµes mÃ©dias: {validation_result['avg_dimensions']:.0f}\")\n",
    "    print(f\"   ğŸ¤– Modelos usados: {', '.join(validation_result['models_used'])}\")\n",
    "else:\n",
    "    print(f\"\\nâŒ Problema na validaÃ§Ã£o: {validation_result.get('error', 'Erro desconhecido')}\")\n",
    "\n",
    "# AnÃ¡lise detalhada de qualidade\n",
    "embeddings_dir = Path(embedding_config[\"output_dir\"])\n",
    "embedding_files = list(embeddings_dir.glob(\"*_embeddings.json\"))\n",
    "\n",
    "quality_stats = {\n",
    "    \"total_embeddings\": 0,\n",
    "    \"total_dimensions\": 0,\n",
    "    \"models_used\": set(),\n",
    "    \"avg_vector_magnitude\": [],\n",
    "    \"empty_embeddings\": 0,\n",
    "    \"dimension_consistency\": True\n",
    "}\n",
    "\n",
    "print(f\"\\nğŸ“ˆ AnÃ¡lise detalhada de {len(embedding_files)} arquivos de embeddings:\")\n",
    "\n",
    "expected_dimensions = embedding_config[\"embedding_dimensions\"]\n",
    "\n",
    "for embedding_file in embedding_files:\n",
    "    try:\n",
    "        with open(embedding_file, 'r', encoding='utf-8') as f:\n",
    "            embedding_data = json.load(f)\n",
    "        \n",
    "        chunks = embedding_data.get(\"chunks_with_embeddings\", [])\n",
    "        \n",
    "        for chunk in chunks:\n",
    "            embedding = chunk.get(\"embedding\", [])\n",
    "            model_name = chunk.get(\"embedding_model\", \"unknown\")\n",
    "            dimensions = chunk.get(\"embedding_dimensions\", 0)\n",
    "            \n",
    "            quality_stats[\"total_embeddings\"] += 1\n",
    "            quality_stats[\"total_dimensions\"] += dimensions\n",
    "            quality_stats[\"models_used\"].add(model_name)\n",
    "            \n",
    "            # Verificar dimensÃµes\n",
    "            if dimensions != expected_dimensions:\n",
    "                quality_stats[\"dimension_consistency\"] = False\n",
    "            \n",
    "            # Verificar embeddings vazios\n",
    "            if not embedding or len(embedding) == 0:\n",
    "                quality_stats[\"empty_embeddings\"] += 1\n",
    "            else:\n",
    "                # Calcular magnitude do vetor\n",
    "                try:\n",
    "                    vector_magnitude = np.linalg.norm(embedding)\n",
    "                    quality_stats[\"avg_vector_magnitude\"].append(vector_magnitude)\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸ Erro ao analisar {embedding_file.name}: {e}\")\n",
    "\n",
    "# EstatÃ­sticas de qualidade\n",
    "if quality_stats[\"total_embeddings\"] > 0:\n",
    "    avg_dimensions = quality_stats[\"total_dimensions\"] / quality_stats[\"total_embeddings\"]\n",
    "    avg_magnitude = np.mean(quality_stats[\"avg_vector_magnitude\"]) if quality_stats[\"avg_vector_magnitude\"] else 0\n",
    "    \n",
    "    print(f\"\\nğŸ“ EstatÃ­sticas de qualidade:\")\n",
    "    print(f\"   ğŸ“Š Embeddings totais: {quality_stats['total_embeddings']:,}\")\n",
    "    print(f\"   ğŸ“ DimensÃµes mÃ©dias: {avg_dimensions:.0f}\")\n",
    "    print(f\"   ğŸ“Š DimensÃµes esperadas: {expected_dimensions}\")\n",
    "    print(f\"   âœ… ConsistÃªncia dimensional: {quality_stats['dimension_consistency']}\")\n",
    "    print(f\"   ğŸ“ˆ Magnitude mÃ©dia dos vetores: {avg_magnitude:.3f}\")\n",
    "    \n",
    "    if quality_stats[\"empty_embeddings\"] > 0:\n",
    "        print(f\"\\nâš ï¸ Problemas encontrados:\")\n",
    "        print(f\"   Embeddings vazios: {quality_stats['empty_embeddings']}\")\n",
    "    \n",
    "    print(f\"\\nğŸ¤– Modelos utilizados:\")\n",
    "    for model in quality_stats[\"models_used\"]:\n",
    "        print(f\"   - {model}\")\n",
    "\n",
    "# Preparar lista de arquivos de embeddings para prÃ³xima etapa\n",
    "embedding_files_info = []\n",
    "for result in successful_embeddings:\n",
    "    embedding_files_info.append({\n",
    "        \"source_chunks_file\": result[\"source_chunks_file\"],\n",
    "        \"embeddings_file\": result[\"embeddings_file\"],\n",
    "        \"embedding_count\": result[\"embedding_count\"],\n",
    "        \"model_name\": result[\"model_name\"]\n",
    "    })\n",
    "\n",
    "print(f\"\\nğŸ“‹ Arquivos de embeddings preparados para prÃ³xima etapa: {len(embedding_files_info)}\")\n",
    "print(\"âœ… ValidaÃ§Ã£o concluÃ­da!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Salvamento dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ’¾ SALVAMENTO DOS RESULTADOS PARA PRÃ“XIMA ETAPA\n",
    "print(\"ğŸ’¾ Salvando resultados da geraÃ§Ã£o de embeddings...\")\n",
    "\n",
    "from pipeline_utils import get_timestamp\n",
    "\n",
    "# Preparar dados de saÃ­da para prÃ³xima etapa\n",
    "stage_output = {\n",
    "    \"stage_info\": {\n",
    "        \"stage_number\": 5,\n",
    "        \"stage_name\": \"embeddings\",\n",
    "        \"completed_at\": get_timestamp(),\n",
    "        \"status\": \"success\" if len(successful_embeddings) > 0 else \"completed_with_warnings\",\n",
    "        \"embedding_duration_seconds\": embedding_duration\n",
    "    },\n",
    "    \n",
    "    \"embedding_config\": embedding_config,\n",
    "    \n",
    "    \"input_files\": {\n",
    "        \"total_chunk_files\": len(chunk_files),\n",
    "        \"available_files\": len(available_chunk_files),\n",
    "        \"processed_files\": len(embedding_results)\n",
    "    },\n",
    "    \n",
    "    \"embedding_files\": embedding_files_info,\n",
    "    \n",
    "    \"embedding_results\": {\n",
    "        \"successful_files\": len(successful_embeddings),\n",
    "        \"failed_files\": len(failed_embeddings),\n",
    "        \"total_embeddings_created\": total_embeddings,\n",
    "        \"total_vector_size_mb\": total_vectors_size_mb\n",
    "    },\n",
    "    \n",
    "    \"quality_analysis\": {\n",
    "        \"total_embeddings\": quality_stats[\"total_embeddings\"],\n",
    "        \"avg_dimensions\": quality_stats[\"total_dimensions\"] / quality_stats[\"total_embeddings\"] if quality_stats[\"total_embeddings\"] > 0 else 0,\n",
    "        \"expected_dimensions\": expected_dimensions,\n",
    "        \"dimension_consistency\": quality_stats[\"dimension_consistency\"],\n",
    "        \"empty_embeddings\": quality_stats[\"empty_embeddings\"],\n",
    "        \"avg_vector_magnitude\": np.mean(quality_stats[\"avg_vector_magnitude\"]) if quality_stats[\"avg_vector_magnitude\"] else 0,\n",
    "        \"models_used\": list(quality_stats[\"models_used\"])\n",
    "    },\n",
    "    \n",
    "    \"statistics\": {\n",
    "        \"files_processed\": len(successful_embeddings),\n",
    "        \"total_embeddings\": total_embeddings,\n",
    "        \"avg_embeddings_per_file\": total_embeddings / len(successful_embeddings) if successful_embeddings else 0,\n",
    "        \"processing_time_seconds\": embedding_duration,\n",
    "        \"processing_speed_embeddings_per_sec\": total_embeddings / embedding_duration if embedding_duration > 0 else 0,\n",
    "        \"total_vector_size_mb\": total_vectors_size_mb,\n",
    "        \"embedding_files_generated\": len(embedding_files)\n",
    "    },\n",
    "    \n",
    "    \"errors\": [\n",
    "        {\n",
    "            \"source_chunks_file\": result[\"source_chunks_file\"],\n",
    "            \"error\": result[\"error\"]\n",
    "        }\n",
    "        for result in failed_embeddings\n",
    "    ],\n",
    "    \n",
    "    \"next_stage_instructions\": {\n",
    "        \"embeddings_directory\": embedding_config[\"output_dir\"],\n",
    "        \"embedding_files_to_store\": [info[\"embeddings_file\"] for info in embedding_files_info],\n",
    "        \"total_embeddings_to_store\": total_embeddings,\n",
    "        \"vector_dimensions\": expected_dimensions,\n",
    "        \"recommended_batch_size\": 100,\n",
    "        \"qdrant_collection_config\": {\n",
    "            \"vector_size\": expected_dimensions,\n",
    "            \"distance_metric\": \"Cosine\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Salvar usando PipelineState\n",
    "state = PipelineState()\n",
    "state.save_stage_data(5, stage_output)\n",
    "\n",
    "# Marcar etapa como concluÃ­da\n",
    "state.mark_stage_completed(5)\n",
    "\n",
    "print(f\"âœ… Resultados salvos: {state.metadata_dir / 'stage_05_embeddings.json'}\")\n",
    "print(f\"âœ… Checkpoint criado: {state.checkpoints_dir / 'stage_05_completed.lock'}\")\n",
    "\n",
    "# Salvar relatÃ³rio detalhado de embeddings\n",
    "embedding_report_path = Path(embedding_config[\"output_dir\"]) / \"embedding_report.json\"\n",
    "with open(embedding_report_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump({\n",
    "        \"timestamp\": get_timestamp(),\n",
    "        \"config\": embedding_config,\n",
    "        \"results\": embedding_results,\n",
    "        \"quality_stats\": {\n",
    "            k: (list(v) if isinstance(v, set) else float(v) if isinstance(v, np.float64) else v) \n",
    "            for k, v in quality_stats.items()\n",
    "        },\n",
    "        \"validation\": validation_result\n",
    "    }, f, indent=2, ensure_ascii=False, default=str)\n",
    "\n",
    "print(f\"ğŸ“ RelatÃ³rio detalhado salvo: {embedding_report_path}\")\n",
    "\n",
    "# Exibir resumo final\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ‰ ETAPA 5 CONCLUÃDA COM SUCESSO!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"ğŸ“Š Resumo da GeraÃ§Ã£o de Embeddings:\")\n",
    "print(f\"   ğŸ“„ Arquivos processados: {len(successful_embeddings)}/{len(available_chunk_files)}\")\n",
    "print(f\"   ğŸ§  Embeddings criados: {total_embeddings:,}\")\n",
    "print(f\"   ğŸ“Š DimensÃµes: {expected_dimensions}\")\n",
    "print(f\"   ğŸ¤– Modelo: {embedding_config['model_name']}\")\n",
    "print(f\"   ğŸ’¾ Tamanho total: {total_vectors_size_mb:.1f} MB\")\n",
    "print(f\"   â±ï¸ Tempo total: {embedding_duration:.1f} segundos\")\n",
    "print(f\"   ğŸ“ LocalizaÃ§Ã£o: {embedding_config['output_dir']}\")\n",
    "\n",
    "if failed_embeddings:\n",
    "    print(f\"   âš ï¸ Avisos: {len(failed_embeddings)} arquivos falharam\")\n",
    "else:\n",
    "    print(f\"   âœ… Status: Todos os arquivos processados com sucesso\")\n",
    "\n",
    "print(f\"\\nğŸš€ Pronto para prÃ³xima etapa: 06_ARMAZENAMENTO_QDRANT.ipynb\")\n",
    "print(f\"ğŸ“‹ {total_embeddings:,} embeddings prontos para armazenamento\")\n",
    "\n",
    "# Exibir progresso do pipeline\n",
    "print(\"\\nğŸ“ˆ Progresso do Pipeline:\")\n",
    "show_pipeline_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… **Etapa 5 ConcluÃ­da!**\n",
    "\n",
    "### ğŸ¯ **O que foi feito:**\n",
    "- âœ… Chunks convertidos em embeddings de alta qualidade\n",
    "- âœ… Modelo BAAI/bge-m3 carregado e utilizado\n",
    "- âœ… Processamento em lotes para eficiÃªncia\n",
    "- âœ… Vetores normalizados (1024 dimensÃµes)\n",
    "- âœ… Qualidade validada e estatÃ­sticas coletadas\n",
    "- âœ… Embeddings organizados e catalogados\n",
    "\n",
    "### ğŸš€ **PrÃ³xima etapa:**\n",
    "**`06_ARMAZENAMENTO_QDRANT.ipynb`** - InserÃ§Ã£o dos vetores no Qdrant\n",
    "\n",
    "### ğŸ“Š **Arquivos gerados:**\n",
    "- `pipeline_data/embeddings/` - Embeddings organizados por documento\n",
    "- `pipeline_data/embeddings/*_embeddings.json` - Vetores com metadados completos\n",
    "- `pipeline_data/metadata/stage_05_embeddings.json` - EstatÃ­sticas e configuraÃ§Ã£o\n",
    "- `pipeline_data/embeddings/embedding_report.json` - RelatÃ³rio detalhado de qualidade\n",
    "- `pipeline_data/checkpoints/stage_05_completed.lock` - Checkpoint de conclusÃ£o\n",
    "\n",
    "### ğŸ“‹ **Dados para prÃ³xima etapa:**\n",
    "- **Embeddings vetorizados:** Prontos para inserÃ§Ã£o no Qdrant\n",
    "- **Metadados preservados:** Origem, chunks, posiÃ§Ãµes\n",
    "- **Qualidade validada:** DimensÃµes corretas, vetores normalizados\n",
    "\n",
    "### ğŸ”§ **Para executar prÃ³xima etapa:**\n",
    "1. Abra o notebook `06_ARMAZENAMENTO_QDRANT.ipynb`\n",
    "2. Execute as cÃ©lulas em sequÃªncia\n",
    "3. Ou use o `00_PIPELINE_MASTER.ipynb` para execuÃ§Ã£o automÃ¡tica\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ§  Embeddings de alta qualidade gerados! Prontos para busca semÃ¢ntica.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}