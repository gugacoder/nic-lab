{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# ğŸ“Š ETAPA 7: VALIDAÃ‡ÃƒO E RESULTADOS\n",
    "\n",
    "## ğŸ¯ **O que esta etapa faz**\n",
    "Executa testes abrangentes de qualidade, performance e funcionalidade do sistema completo de busca semÃ¢ntica, validando se o pipeline NIC ETL estÃ¡ funcionando corretamente.\n",
    "\n",
    "## ğŸ¤” **Por que esta etapa Ã© necessÃ¡ria**\n",
    "Para garantir que o sistema estÃ¡ pronto para uso, precisamos:\n",
    "- âœ… **Validar qualidade** da busca semÃ¢ntica\n",
    "- âš¡ **Medir performance** de resposta e precisÃ£o\n",
    "- ğŸ” **Testar cenÃ¡rios reais** de uso\n",
    "- ğŸ“Š **Gerar relatÃ³rios** de qualidade e mÃ©tricas\n",
    "- ğŸ›¡ï¸ **Verificar integridade** de todos os dados\n",
    "\n",
    "## âš™ï¸ **Como funciona**\n",
    "1. **Valida pipeline completo** - todas as etapas executadas\n",
    "2. **Testa busca semÃ¢ntica** - consultas variadas e relevÃ¢ncia\n",
    "3. **Mede performance** - tempos de resposta e throughput\n",
    "4. **Analisa qualidade** - precisÃ£o dos resultados\n",
    "5. **Testa filtragem** - metadados e campos especÃ­ficos\n",
    "6. **Gera relatÃ³rio final** - mÃ©tricas e recomendaÃ§Ãµes\n",
    "\n",
    "## ğŸ“Š **Tipos de validaÃ§Ã£o executados**\n",
    "- `Integridade de Dados`: Contagens, consistÃªncia, metadados\n",
    "- `Qualidade de Busca`: RelevÃ¢ncia, precisÃ£o, recall\n",
    "- `Performance`: Tempos de resposta, throughput\n",
    "- `Funcionalidade`: Filtros, ordenaÃ§Ã£o, paginaÃ§Ã£o\n",
    "- `Robustez`: Consultas edge case, stress test\n",
    "\n",
    "## ğŸ‘ï¸ **O que esperar de saÃ­da**\n",
    "- ğŸ“Š **RelatÃ³rio completo** de validaÃ§Ã£o com mÃ©tricas\n",
    "- âœ… **Status de qualidade** para cada componente\n",
    "- âš¡ **Benchmarks** de performance\n",
    "- ğŸ” **Exemplos de busca** funcionais\n",
    "- ğŸ“‹ **RecomendaÃ§Ãµes** de otimizaÃ§Ã£o (se aplicÃ¡vel)\n",
    "\n",
    "## âš ï¸ **Pontos importantes**\n",
    "- **Requer todas as etapas anteriores** concluÃ­das\n",
    "- **Testes nÃ£o modificam dados** - apenas leitura e consulta\n",
    "- **Pode demorar** dependendo do volume de dados\n",
    "- **Resultados sÃ£o determinÃ­sticos** - repetÃ­veis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## ğŸ›¡ï¸ VerificaÃ§Ã£o de DependÃªncias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ›¡ï¸ VERIFICAÃ‡ÃƒO AUTOMÃTICA DE DEPENDÃŠNCIAS\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Adicionar biblioteca ao path\n",
    "sys.path.insert(0, str(Path().parent / \"src\"))\n",
    "\n",
    "from pipeline_utils import (\n",
    "    PipelineState, \n",
    "    check_prerequisites, \n",
    "    show_pipeline_progress\n",
    ")\n",
    "\n",
    "print(\"ğŸ“Š ETAPA 7: VALIDAÃ‡ÃƒO E RESULTADOS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ğŸ•’ Iniciado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Verificar dependÃªncias\n",
    "CURRENT_STAGE = 7\n",
    "prerequisites_ok = check_prerequisites(CURRENT_STAGE)\n",
    "\n",
    "if not prerequisites_ok:\n",
    "    print(\"\\nâŒ ERRO: DependÃªncias nÃ£o atendidas!\")\n",
    "    print(\"ğŸ“‹ Execute primeiro TODAS as etapas anteriores:\")\n",
    "    print(\"   1. 01_FUNDACAO_PREPARACAO.ipynb\")\n",
    "    print(\"   2. 02_COLETA_GITLAB.ipynb\")\n",
    "    print(\"   3. 03_PROCESSAMENTO_DOCLING.ipynb\")\n",
    "    print(\"   4. 04_SEGMENTACAO_CHUNKS.ipynb\")\n",
    "    print(\"   5. 05_GERACAO_EMBEDDINGS.ipynb\")\n",
    "    print(\"   6. 06_ARMAZENAMENTO_QDRANT.ipynb\")\n",
    "    \n",
    "    show_pipeline_progress()\n",
    "    raise RuntimeError(\"DependÃªncias nÃ£o atendidas - execute etapas anteriores primeiro\")\n",
    "\n",
    "print(\"\\nâœ… DependÃªncias verificadas - pipeline completo!\")\n",
    "print(\"ğŸ“ˆ Progresso atual do pipeline:\")\n",
    "show_pipeline_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## ğŸ“‹ ConfiguraÃ§Ã£o de ValidaÃ§Ã£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“‹ CONFIGURAÃ‡ÃƒO DOS TESTES DE VALIDAÃ‡ÃƒO\n",
    "print(\"ğŸ“‹ Configurando parÃ¢metros de validaÃ§Ã£o...\")\n",
    "\n",
    "# Carregar configuraÃ§Ãµes de todas as etapas\n",
    "state = PipelineState()\n",
    "all_stage_data = {}\n",
    "\n",
    "for stage in range(1, 7):\n",
    "    try:\n",
    "        all_stage_data[stage] = state.load_stage_data(stage)\n",
    "        print(f\"   âœ… Etapa {stage}: {all_stage_data[stage]['stage_info']['stage_name']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Etapa {stage}: Erro ao carregar - {e}\")\n",
    "        raise\n",
    "\n",
    "# ğŸ¯ PARÃ‚METROS DE VALIDAÃ‡ÃƒO\n",
    "validation_config = {\n",
    "    # Testes de busca\n",
    "    \"search_test_queries\": [\n",
    "        \"configuraÃ§Ã£o de sistema\",\n",
    "        \"como instalar\",\n",
    "        \"procedimento de backup\",\n",
    "        \"troubleshooting erro\",\n",
    "        \"manual do usuÃ¡rio\"\n",
    "    ],\n",
    "    \"max_search_results\": 10,\n",
    "    \"min_relevance_score\": 0.1,\n",
    "    \n",
    "    # Performance\n",
    "    \"max_search_time_ms\": 5000,  # 5 segundos\n",
    "    \"concurrent_search_tests\": 3,\n",
    "    \"stress_test_queries\": 20,\n",
    "    \n",
    "    # Qualidade\n",
    "    \"min_collection_size\": 100,  # MÃ­nimo de vetores esperado\n",
    "    \"expected_dimensions\": 1024,\n",
    "    \"check_metadata_completeness\": True,\n",
    "    \n",
    "    # RelatÃ³rios\n",
    "    \"generate_examples\": True,\n",
    "    \"detailed_analysis\": True,\n",
    "    \"export_metrics\": True\n",
    "}\n",
    "\n",
    "# Extrair configuraÃ§Ãµes importantes\n",
    "qdrant_config = all_stage_data[6][\"qdrant_config\"]\n",
    "collection_status = all_stage_data[6][\"collection_status\"]\n",
    "total_embeddings = collection_status[\"vectors_count\"]\n",
    "\n",
    "print(\"\\nğŸ“Š ConfiguraÃ§Ã£o de validaÃ§Ã£o:\")\n",
    "print(f\"   ğŸ” Consultas de teste: {len(validation_config['search_test_queries'])}\")\n",
    "print(f\"   ğŸ“Š Resultados por busca: {validation_config['max_search_results']}\")\n",
    "print(f\"   â±ï¸ Tempo mÃ¡ximo: {validation_config['max_search_time_ms']}ms\")\n",
    "print(f\"   ğŸ§ª Testes de stress: {validation_config['stress_test_queries']}\")\n",
    "print(f\"   ğŸ’¾ Collection: {qdrant_config['collection_name']}\")\n",
    "print(f\"   ğŸ“ˆ Vetores disponÃ­veis: {total_embeddings:,}\")\n",
    "\n",
    "if total_embeddings < validation_config[\"min_collection_size\"]:\n",
    "    print(f\"   âš ï¸ Aviso: Collection pequena (< {validation_config['min_collection_size']} vetores)\")\n",
    "\n",
    "print(\"\\nâœ… ConfiguraÃ§Ã£o de validaÃ§Ã£o pronta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## ğŸ” ValidaÃ§Ã£o da Integridade dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” VALIDAÃ‡ÃƒO DA INTEGRIDADE DOS DADOS\n",
    "print(\"ğŸ” Validando integridade dos dados do pipeline...\")\n",
    "\n",
    "from qdrant_utils import get_collection_info\n",
    "\n",
    "integrity_results = {\n",
    "    \"pipeline_stages\": {},\n",
    "    \"data_flow\": {},\n",
    "    \"consistency_checks\": {},\n",
    "    \"overall_health\": \"unknown\"\n",
    "}\n",
    "\n",
    "# Verificar cada etapa do pipeline\n",
    "print(\"\\nğŸ“Š Verificando integridade por etapa:\")\n",
    "\n",
    "stage_names = {\n",
    "    1: \"FundaÃ§Ã£o\",\n",
    "    2: \"GitLab\", \n",
    "    3: \"Docling\",\n",
    "    4: \"Chunking\",\n",
    "    5: \"Embeddings\",\n",
    "    6: \"Qdrant\"\n",
    "}\n",
    "\n",
    "for stage_num, stage_data in all_stage_data.items():\n",
    "    stage_name = stage_names[stage_num]\n",
    "    \n",
    "    # Verificar status da etapa\n",
    "    stage_status = stage_data.get(\"stage_info\", {}).get(\"status\", \"unknown\")\n",
    "    completed_at = stage_data.get(\"stage_info\", {}).get(\"completed_at\", \"unknown\")\n",
    "    \n",
    "    integrity_results[\"pipeline_stages\"][stage_num] = {\n",
    "        \"name\": stage_name,\n",
    "        \"status\": stage_status,\n",
    "        \"completed_at\": completed_at,\n",
    "        \"has_errors\": len(stage_data.get(\"errors\", [])) > 0,\n",
    "        \"error_count\": len(stage_data.get(\"errors\", []))\n",
    "    }\n",
    "    \n",
    "    status_icon = \"âœ…\" if stage_status == \"success\" else \"âš ï¸\" if \"warning\" in stage_status else \"âŒ\"\n",
    "    error_info = f\" ({len(stage_data.get('errors', []))} erros)\" if stage_data.get(\"errors\") else \"\"\n",
    "    print(f\"   {status_icon} Etapa {stage_num} ({stage_name}): {stage_status}{error_info}\")\n",
    "\n",
    "# Verificar fluxo de dados entre etapas\n",
    "print(\"\\nğŸ“ˆ Verificando fluxo de dados:\")\n",
    "\n",
    "# GitLab -> Docling\n",
    "gitlab_files = len(all_stage_data[2].get(\"local_files\", []))\n",
    "docling_files = len(all_stage_data.get(3, {}).get(\"processed_documents\", []))\n",
    "print(f\"   ğŸ“¥ GitLab â†’ Docling: {gitlab_files} â†’ {docling_files} documentos\")\n",
    "\n",
    "# Docling -> Chunking\n",
    "chunking_files = len(all_stage_data.get(4, {}).get(\"chunk_files\", []))\n",
    "total_chunks = all_stage_data.get(4, {}).get(\"chunking_results\", {}).get(\"total_chunks_created\", 0)\n",
    "print(f\"   âš™ï¸ Docling â†’ Chunks: {docling_files} â†’ {chunking_files} arquivos ({total_chunks:,} chunks)\")\n",
    "\n",
    "# Chunking -> Embeddings\n",
    "embedding_files = len(all_stage_data.get(5, {}).get(\"embedding_files\", []))\n",
    "total_embeddings_created = all_stage_data.get(5, {}).get(\"embedding_results\", {}).get(\"total_embeddings_created\", 0)\n",
    "print(f\"   ğŸ”ª Chunks â†’ Embeddings: {chunking_files} â†’ {embedding_files} arquivos ({total_embeddings_created:,} embeddings)\")\n",
    "\n",
    "# Embeddings -> Qdrant\n",
    "qdrant_stored = all_stage_data.get(6, {}).get(\"collection_status\", {}).get(\"vectors_count\", 0)\n",
    "print(f\"   ğŸ§  Embeddings â†’ Qdrant: {total_embeddings_created:,} â†’ {qdrant_stored:,} vetores\")\n",
    "\n",
    "# Verificar consistÃªncia de dados\n",
    "print(\"\\nğŸ”„ Verificando consistÃªncia:\")\n",
    "\n",
    "# Taxa de retenÃ§Ã£o entre etapas\n",
    "if gitlab_files > 0:\n",
    "    docling_retention = (docling_files / gitlab_files) * 100\n",
    "    print(f\"   ğŸ“Š RetenÃ§Ã£o GitLabâ†’Docling: {docling_retention:.1f}%\")\n",
    "    \n",
    "if total_embeddings_created > 0:\n",
    "    qdrant_retention = (qdrant_stored / total_embeddings_created) * 100\n",
    "    print(f\"   ğŸ“Š RetenÃ§Ã£o Embeddingsâ†’Qdrant: {qdrant_retention:.1f}%\")\n",
    "\n",
    "# Verificar estado atual da collection no Qdrant\n",
    "print(\"\\nğŸ’¾ Verificando estado atual do Qdrant:\")\n",
    "current_collection_info = get_collection_info(\n",
    "    qdrant_config[\"url\"],\n",
    "    qdrant_config[\"collection_name\"],\n",
    "    all_stage_data[1][\"qdrant\"][\"api_key\"]  # API key da etapa 1\n",
    ")\n",
    "\n",
    "if current_collection_info:\n",
    "    print(f\"   ğŸ“¦ Collection: {current_collection_info['collection_name']}\")\n",
    "    print(f\"   ğŸ“Š Vetores atuais: {current_collection_info['vectors_count']:,}\")\n",
    "    print(f\"   ğŸ“„ Pontos atuais: {current_collection_info['points_count']:,}\")\n",
    "    print(f\"   ğŸ“ DimensÃµes: {current_collection_info['config']['vector_size']}\")\n",
    "    \n",
    "    # Verificar se dimensÃµes estÃ£o corretas\n",
    "    expected_dims = validation_config[\"expected_dimensions\"]\n",
    "    actual_dims = current_collection_info['config']['vector_size']\n",
    "    \n",
    "    if actual_dims == expected_dims:\n",
    "        print(f\"   âœ… DimensÃµes corretas: {actual_dims}\")\n",
    "    else:\n",
    "        print(f\"   âŒ DimensÃµes incorretas: {actual_dims} (esperado: {expected_dims})\")\n",
    "else:\n",
    "    print(\"   âŒ NÃ£o foi possÃ­vel verificar collection\")\n",
    "\n",
    "# Determinar saÃºde geral\n",
    "all_stages_ok = all(status[\"status\"] in [\"success\", \"completed_with_warnings\"] \n",
    "                   for status in integrity_results[\"pipeline_stages\"].values())\n",
    "data_flow_ok = qdrant_stored > validation_config[\"min_collection_size\"]\n",
    "qdrant_accessible = current_collection_info is not None\n",
    "\n",
    "if all_stages_ok and data_flow_ok and qdrant_accessible:\n",
    "    integrity_results[\"overall_health\"] = \"healthy\"\n",
    "    health_icon = \"âœ…\"\n",
    "    health_msg = \"Sistema Ã­ntegro e funcional\"\n",
    "elif all_stages_ok and qdrant_accessible:\n",
    "    integrity_results[\"overall_health\"] = \"functional\"\n",
    "    health_icon = \"âš ï¸\"\n",
    "    health_msg = \"Sistema funcional com avisos\"\n",
    "else:\n",
    "    integrity_results[\"overall_health\"] = \"issues\"\n",
    "    health_icon = \"âŒ\"\n",
    "    health_msg = \"Sistema com problemas detectados\"\n",
    "\n",
    "print(f\"\\n{health_icon} Status geral da integridade: {health_msg}\")\n",
    "print(\"\\nâœ… ValidaÃ§Ã£o de integridade concluÃ­da!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## ğŸ” Testes de Busca SemÃ¢ntica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” TESTES DE BUSCA SEMÃ‚NTICA\n",
    "print(\"ğŸ” Executando testes de busca semÃ¢ntica...\")\n",
    "\n",
    "from qdrant_utils import search_similar_vectors\n",
    "from embedding_utils import generate_embeddings\n",
    "import statistics\n",
    "\n",
    "search_test_results = {\n",
    "    \"query_tests\": [],\n",
    "    \"performance_metrics\": {},\n",
    "    \"quality_analysis\": {},\n",
    "    \"overall_score\": 0\n",
    "}\n",
    "\n",
    "# ConfiguraÃ§Ã£o para busca\n",
    "embedding_model = all_stage_data[5][\"embedding_config\"][\"model_name\"]\n",
    "api_key = all_stage_data[1][\"qdrant\"][\"api_key\"]\n",
    "\n",
    "print(f\"\\nğŸ¤– Modelo de embeddings: {embedding_model}\")\n",
    "print(f\"ğŸ” Executando {len(validation_config['search_test_queries'])} consultas de teste...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "all_search_times = []\n",
    "all_result_counts = []\n",
    "all_relevance_scores = []\n",
    "\n",
    "for i, query in enumerate(validation_config[\"search_test_queries\"], 1):\n",
    "    print(f\"\\nğŸ” Teste {i}: '{query}'\")\n",
    "    \n",
    "    test_result = {\n",
    "        \"query\": query,\n",
    "        \"success\": False,\n",
    "        \"search_time_ms\": 0,\n",
    "        \"result_count\": 0,\n",
    "        \"relevance_scores\": [],\n",
    "        \"avg_relevance\": 0,\n",
    "        \"error\": None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Gerar embedding da consulta\n",
    "        print(f\"   ğŸ§  Gerando embedding...\")\n",
    "        query_start = time.time()\n",
    "        query_embeddings = generate_embeddings([query], embedding_model)\n",
    "        embedding_time = (time.time() - query_start) * 1000\n",
    "        \n",
    "        if not query_embeddings or len(query_embeddings) == 0:\n",
    "            raise ValueError(\"Falha ao gerar embedding da consulta\")\n",
    "        \n",
    "        query_vector = query_embeddings[0]\n",
    "        print(f\"   âœ… Embedding gerado ({len(query_vector)} dims) em {embedding_time:.1f}ms\")\n",
    "        \n",
    "        # Executar busca\n",
    "        print(f\"   ğŸ” Executando busca...\")\n",
    "        search_start = time.time()\n",
    "        \n",
    "        search_results = search_similar_vectors(\n",
    "            qdrant_config[\"url\"],\n",
    "            qdrant_config[\"collection_name\"],\n",
    "            api_key,\n",
    "            query_vector,\n",
    "            limit=validation_config[\"max_search_results\"]\n",
    "        )\n",
    "        \n",
    "        search_time = (time.time() - search_start) * 1000\n",
    "        total_time = embedding_time + search_time\n",
    "        \n",
    "        # Analisar resultados\n",
    "        if search_results:\n",
    "            result_count = len(search_results)\n",
    "            relevance_scores = [r.get(\"score\", 0) for r in search_results]\n",
    "            avg_relevance = statistics.mean(relevance_scores) if relevance_scores else 0\n",
    "            \n",
    "            print(f\"   âœ… {result_count} resultados em {total_time:.1f}ms\")\n",
    "            print(f\"   ğŸ“Š RelevÃ¢ncia mÃ©dia: {avg_relevance:.3f}\")\n",
    "            \n",
    "            # Mostrar top 3 resultados\n",
    "            for j, result in enumerate(search_results[:3], 1):\n",
    "                score = result.get(\"score\", 0)\n",
    "                result_id = str(result.get(\"id\", \"unknown\"))[:20] + \"...\"\n",
    "                payload = result.get(\"payload\", {})\n",
    "                text_preview = payload.get(\"text\", \"\")[:50] + \"...\" if payload.get(\"text\") else \"sem texto\"\n",
    "                print(f\"     {j}. Score: {score:.3f} | ID: {result_id} | '{text_preview}'\")\n",
    "            \n",
    "            test_result.update({\n",
    "                \"success\": True,\n",
    "                \"search_time_ms\": total_time,\n",
    "                \"result_count\": result_count,\n",
    "                \"relevance_scores\": relevance_scores,\n",
    "                \"avg_relevance\": avg_relevance\n",
    "            })\n",
    "            \n",
    "            # Coletar mÃ©tricas globais\n",
    "            all_search_times.append(total_time)\n",
    "            all_result_counts.append(result_count)\n",
    "            all_relevance_scores.extend(relevance_scores)\n",
    "            \n",
    "        else:\n",
    "            print(f\"   âš ï¸ Busca nÃ£o retornou resultados\")\n",
    "            test_result[\"success\"] = True  # Tecnicamente funcionou\n",
    "            test_result[\"search_time_ms\"] = total_time\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Erro: {e}\")\n",
    "        test_result[\"error\"] = str(e)\n",
    "    \n",
    "    search_test_results[\"query_tests\"].append(test_result)\n",
    "\n",
    "# Calcular mÃ©tricas de performance\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ğŸ“Š MÃ‰TRICAS DE PERFORMANCE:\")\n",
    "\n",
    "successful_tests = [t for t in search_test_results[\"query_tests\"] if t[\"success\"]]\n",
    "failed_tests = [t for t in search_test_results[\"query_tests\"] if not t[\"success\"]]\n",
    "\n",
    "if all_search_times:\n",
    "    avg_search_time = statistics.mean(all_search_times)\n",
    "    max_search_time = max(all_search_times)\n",
    "    min_search_time = min(all_search_times)\n",
    "    \n",
    "    print(f\"   â±ï¸ Tempo mÃ©dio: {avg_search_time:.1f}ms\")\n",
    "    print(f\"   âš¡ Tempo mÃ­nimo: {min_search_time:.1f}ms\")\n",
    "    print(f\"   ğŸŒ Tempo mÃ¡ximo: {max_search_time:.1f}ms\")\n",
    "    \n",
    "    if avg_search_time <= validation_config[\"max_search_time_ms\"]:\n",
    "        print(f\"   âœ… Performance: EXCELENTE (< {validation_config['max_search_time_ms']}ms)\")\n",
    "    else:\n",
    "        print(f\"   âš ï¸ Performance: LENTA (> {validation_config['max_search_time_ms']}ms)\")\n",
    "\n",
    "if all_relevance_scores:\n",
    "    avg_relevance = statistics.mean(all_relevance_scores)\n",
    "    max_relevance = max(all_relevance_scores)\n",
    "    min_relevance = min(all_relevance_scores)\n",
    "    \n",
    "    print(f\"   ğŸ“Š RelevÃ¢ncia mÃ©dia: {avg_relevance:.3f}\")\n",
    "    print(f\"   ğŸ“ˆ RelevÃ¢ncia mÃ¡xima: {max_relevance:.3f}\")\n",
    "    print(f\"   ğŸ“‰ RelevÃ¢ncia mÃ­nima: {min_relevance:.3f}\")\n",
    "\n",
    "if all_result_counts:\n",
    "    avg_results = statistics.mean(all_result_counts)\n",
    "    print(f\"   ğŸ“„ Resultados mÃ©dios: {avg_results:.1f}\")\n",
    "\n",
    "success_rate = (len(successful_tests) / len(search_test_results[\"query_tests\"]) * 100) if search_test_results[\"query_tests\"] else 0\n",
    "print(f\"   âœ… Taxa de sucesso: {success_rate:.1f}% ({len(successful_tests)}/{len(search_test_results['query_tests'])})\")\n",
    "\n",
    "# Armazenar mÃ©tricas\n",
    "search_test_results[\"performance_metrics\"] = {\n",
    "    \"avg_search_time_ms\": statistics.mean(all_search_times) if all_search_times else 0,\n",
    "    \"max_search_time_ms\": max(all_search_times) if all_search_times else 0,\n",
    "    \"min_search_time_ms\": min(all_search_times) if all_search_times else 0,\n",
    "    \"avg_relevance_score\": statistics.mean(all_relevance_scores) if all_relevance_scores else 0,\n",
    "    \"avg_results_per_query\": statistics.mean(all_result_counts) if all_result_counts else 0,\n",
    "    \"success_rate_percent\": success_rate\n",
    "}\n",
    "\n",
    "# Calcular score geral\n",
    "performance_score = 100 if avg_search_time <= validation_config[\"max_search_time_ms\"] else max(0, 100 - (avg_search_time - validation_config[\"max_search_time_ms\"]) / 100)\n",
    "relevance_score = (avg_relevance * 100) if all_relevance_scores else 0\n",
    "overall_score = (success_rate + performance_score + relevance_score) / 3\n",
    "\n",
    "search_test_results[\"overall_score\"] = overall_score\n",
    "\n",
    "print(f\"\\nğŸ† Score geral de busca: {overall_score:.1f}/100\")\n",
    "print(\"\\nâœ… Testes de busca semÃ¢ntica concluÃ­dos!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## âš¡ Testes de Performance e Stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš¡ TESTES DE PERFORMANCE E STRESS\n",
    "print(\"âš¡ Executando testes de performance e stress...\")\n",
    "\n",
    "import concurrent.futures\n",
    "import random\n",
    "\n",
    "stress_test_results = {\n",
    "    \"concurrent_tests\": [],\n",
    "    \"stress_tests\": [],\n",
    "    \"throughput_metrics\": {},\n",
    "    \"stability_score\": 0\n",
    "}\n",
    "\n",
    "# Teste de busca concorrente\n",
    "print(\"\\nğŸ”„ Teste de busca concorrente...\")\n",
    "\n",
    "def concurrent_search_test(query_text, test_id):\n",
    "    \"\"\"Executa uma busca e mede o tempo\"\"\"\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Gerar embedding\n",
    "        query_embeddings = generate_embeddings([query_text], embedding_model)\n",
    "        if not query_embeddings:\n",
    "            return {\"success\": False, \"error\": \"Falha no embedding\", \"test_id\": test_id}\n",
    "        \n",
    "        # Buscar\n",
    "        results = search_similar_vectors(\n",
    "            qdrant_config[\"url\"],\n",
    "            qdrant_config[\"collection_name\"],\n",
    "            api_key,\n",
    "            query_embeddings[0],\n",
    "            limit=5\n",
    "        )\n",
    "        \n",
    "        total_time = (time.time() - start_time) * 1000\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"test_id\": test_id,\n",
    "            \"query\": query_text,\n",
    "            \"time_ms\": total_time,\n",
    "            \"result_count\": len(results) if results else 0\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"test_id\": test_id,\n",
    "            \"query\": query_text,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "# Executar testes concorrentes\n",
    "concurrent_queries = validation_config[\"search_test_queries\"] * validation_config[\"concurrent_search_tests\"]\n",
    "print(f\"   ğŸš€ Executando {len(concurrent_queries)} buscas simultÃ¢neas...\")\n",
    "\n",
    "concurrent_start_time = time.time()\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=validation_config[\"concurrent_search_tests\"]) as executor:\n",
    "    future_to_query = {\n",
    "        executor.submit(concurrent_search_test, query, i): (query, i) \n",
    "        for i, query in enumerate(concurrent_queries)\n",
    "    }\n",
    "    \n",
    "    concurrent_results = []\n",
    "    for future in concurrent.futures.as_completed(future_to_query):\n",
    "        result = future.result()\n",
    "        concurrent_results.append(result)\n",
    "\n",
    "concurrent_total_time = (time.time() - concurrent_start_time) * 1000\n",
    "\n",
    "# Analisar resultados concorrentes\n",
    "successful_concurrent = [r for r in concurrent_results if r[\"success\"]]\n",
    "failed_concurrent = [r for r in concurrent_results if not r[\"success\"]]\n",
    "\n",
    "if successful_concurrent:\n",
    "    concurrent_times = [r[\"time_ms\"] for r in successful_concurrent]\n",
    "    avg_concurrent_time = statistics.mean(concurrent_times)\n",
    "    total_throughput = len(successful_concurrent) / (concurrent_total_time / 1000)  # queries/second\n",
    "    \n",
    "    print(f\"   âœ… Sucessos: {len(successful_concurrent)}/{len(concurrent_results)}\")\n",
    "    print(f\"   â±ï¸ Tempo mÃ©dio: {avg_concurrent_time:.1f}ms\")\n",
    "    print(f\"   ğŸš€ Throughput: {total_throughput:.1f} consultas/segundo\")\n",
    "    print(f\"   ğŸ•’ Tempo total: {concurrent_total_time:.1f}ms\")\nelse:\n",
    "    print(f\"   âŒ Todos os testes concorrentes falharam\")\n\n",
    "# Teste de stress com muitas consultas\n",
    "print(f\"\\nğŸ§ª Teste de stress ({validation_config['stress_test_queries']} consultas)...\")\n",
    "\n",
    "stress_queries = []\n",
    "base_words = [\"sistema\", \"configuraÃ§Ã£o\", \"manual\", \"erro\", \"instalaÃ§Ã£o\", \"backup\", \"usuÃ¡rio\", \"rede\", \"servidor\", \"dados\"]\n",
    "for i in range(validation_config[\"stress_test_queries\"]):\n",
    "    # Gerar consultas variadas\n",
    "    query_words = random.sample(base_words, random.randint(1, 3))\n",
    "    stress_queries.append(\" \".join(query_words))\n",
    "\n",
    "stress_start_time = time.time()\n",
    "stress_results = []\n",
    "\n",
    "for i, query in enumerate(stress_queries):\n",
    "    if (i + 1) % 5 == 0:\n",
    "        print(f\"   ğŸ”„ Progresso: {i + 1}/{len(stress_queries)}\")\n",
    "    \n",
    "    result = concurrent_search_test(query, f\"stress_{i}\")\n",
    "    stress_results.append(result)\n",
    "\n",
    "stress_total_time = (time.time() - stress_start_time) * 1000\n",
    "\n",
    "# Analisar resultados de stress\n",
    "successful_stress = [r for r in stress_results if r[\"success\"]]\n",
    "failed_stress = [r for r in stress_results if not r[\"success\"]]\n",
    "\n",
    "if successful_stress:\n",
    "    stress_times = [r[\"time_ms\"] for r in successful_stress]\n",
    "    avg_stress_time = statistics.mean(stress_times)\n",
    "    stress_throughput = len(successful_stress) / (stress_total_time / 1000)\n",
    "    \n",
    "    print(f\"   âœ… Sucessos: {len(successful_stress)}/{len(stress_results)}\")\n",
    "    print(f\"   â±ï¸ Tempo mÃ©dio: {avg_stress_time:.1f}ms\")\n",
    "    print(f\"   ğŸš€ Throughput: {stress_throughput:.1f} consultas/segundo\")\n",
    "    print(f\"   ğŸ•’ Tempo total: {stress_total_time:.1f}ms\")\n",
    "\n",
    "# Calcular score de estabilidade\n",
    "concurrent_success_rate = (len(successful_concurrent) / len(concurrent_results) * 100) if concurrent_results else 0\n",
    "stress_success_rate = (len(successful_stress) / len(stress_results) * 100) if stress_results else 0\n",
    "avg_stability = (concurrent_success_rate + stress_success_rate) / 2\n",
    "\n",
    "stress_test_results.update({\n",
    "    \"concurrent_tests\": concurrent_results,\n",
    "    \"stress_tests\": stress_results,\n",
    "    \"throughput_metrics\": {\n",
    "        \"concurrent_throughput_qps\": total_throughput if successful_concurrent else 0,\n",
    "        \"stress_throughput_qps\": stress_throughput if successful_stress else 0,\n",
    "        \"concurrent_success_rate\": concurrent_success_rate,\n",
    "        \"stress_success_rate\": stress_success_rate\n",
    "    },\n",
    "    \"stability_score\": avg_stability\n",
    "})\n",
    "\n",
    "print(f\"\\nğŸ† Score de estabilidade: {avg_stability:.1f}%\")\n",
    "print(\"\\nâœ… Testes de performance concluÃ­dos!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## ğŸ“Š RelatÃ³rio Final de ValidaÃ§Ã£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š GERAÃ‡ÃƒO DO RELATÃ“RIO FINAL DE VALIDAÃ‡ÃƒO\n",
    "print(\"ğŸ“Š Gerando relatÃ³rio final de validaÃ§Ã£o...\")\n",
    "\n",
    "from pipeline_utils import get_timestamp\n",
    "\n",
    "# Compilar mÃ©tricas finais\n",
    "final_validation_report = {\n",
    "    \"validation_info\": {\n",
    "        \"stage_number\": 7,\n",
    "        \"stage_name\": \"validation\",\n",
    "        \"completed_at\": get_timestamp(),\n",
    "        \"pipeline_version\": \"NIC ETL v1.0\",\n",
    "        \"validation_duration_minutes\": 0  # SerÃ¡ calculado no final\n",
    "    },\n",
    "    \n",
    "    \"pipeline_summary\": {\n",
    "        \"total_stages\": 7,\n",
    "        \"completed_stages\": len([s for s in integrity_results[\"pipeline_stages\"].values() if s[\"status\"] in [\"success\", \"completed_with_warnings\"]]),\n",
    "        \"total_documents_processed\": gitlab_files,\n",
    "        \"total_chunks_created\": total_chunks,\n",
    "        \"total_embeddings_generated\": total_embeddings_created,\n",
    "        \"total_vectors_stored\": qdrant_stored,\n",
    "        \"overall_pipeline_health\": integrity_results[\"overall_health\"]\n",
    "    },\n",
    "    \n",
    "    \"integrity_results\": integrity_results,\n",
    "    \"search_test_results\": search_test_results,\n",
    "    \"stress_test_results\": stress_test_results,\n",
    "    \n",
    "    \"quality_metrics\": {\n",
    "        \"data_integrity_score\": 100 if integrity_results[\"overall_health\"] == \"healthy\" else 75 if integrity_results[\"overall_health\"] == \"functional\" else 25,\n",
    "        \"search_quality_score\": search_test_results[\"overall_score\"],\n",
    "        \"performance_stability_score\": stress_test_results[\"stability_score\"],\n",
    "        \"overall_system_score\": 0  # SerÃ¡ calculado\n",
    "    },\n",
    "    \n",
    "    \"recommendations\": [],\n",
    "    \"next_steps\": []\n",
    "}\n",
    "\n",
    "# Calcular score geral do sistema\n",
    "quality_metrics = final_validation_report[\"quality_metrics\"]\n",
    "overall_system_score = (\n",
    "    quality_metrics[\"data_integrity_score\"] * 0.3 +\n",
    "    quality_metrics[\"search_quality_score\"] * 0.4 +\n",
    "    quality_metrics[\"performance_stability_score\"] * 0.3\n",
    ")\n",
    "quality_metrics[\"overall_system_score\"] = overall_system_score\n",
    "\n",
    "# Gerar recomendaÃ§Ãµes baseadas nos resultados\n",
    "recommendations = []\n",
    "next_steps = []\n",
    "\n",
    "if integrity_results[\"overall_health\"] == \"healthy\":\n",
    "    recommendations.append(\"âœ… Sistema estÃ¡ funcionando corretamente\")\n",
    "    next_steps.append(\"Sistema pronto para uso em produÃ§Ã£o\")\n",
    "elif integrity_results[\"overall_health\"] == \"functional\":\n",
    "    recommendations.append(\"âš ï¸ Sistema funcional mas com avisos - revisar logs\")\n",
    "    next_steps.append(\"Investigar avisos antes de usar em produÃ§Ã£o\")\n",
    "else:\n",
    "    recommendations.append(\"âŒ Sistema com problemas - necessÃ¡rio correÃ§Ã£o\")\n",
    "    next_steps.append(\"Corrigir problemas identificados antes de continuar\")\n",
    "\n",
    "if search_test_results[\"overall_score\"] >= 80:\n",
    "    recommendations.append(\"âœ… Qualidade de busca excelente\")\n",
    "elif search_test_results[\"overall_score\"] >= 60:\n",
    "    recommendations.append(\"âš ï¸ Qualidade de busca adequada mas pode melhorar\")\n",
    "    next_steps.append(\"Considerar fine-tuning do modelo de embeddings\")\n",
    "else:\n",
    "    recommendations.append(\"âŒ Qualidade de busca baixa - revisar configuraÃ§Ãµes\")\n",
    "    next_steps.append(\"Revisar modelo de embeddings e parÃ¢metros de busca\")\n",
    "\n",
    "if stress_test_results[\"stability_score\"] >= 95:\n",
    "    recommendations.append(\"âœ… Excelente estabilidade sob carga\")\n",
    "elif stress_test_results[\"stability_score\"] >= 80:\n",
    "    recommendations.append(\"âš ï¸ Boa estabilidade com algumas falhas\")\n",
    "    next_steps.append(\"Monitorar performance em produÃ§Ã£o\")\n",
    "else:\n",
    "    recommendations.append(\"âŒ Problemas de estabilidade sob carga\")\n",
    "    next_steps.append(\"Otimizar performance e configuraÃ§Ãµes de timeout\")\n",
    "\n",
    "if qdrant_stored < validation_config[\"min_collection_size\"]:\n",
    "    recommendations.append(f\"âš ï¸ Collection pequena ({qdrant_stored} vetores) - adicionar mais documentos\")\n",
    "    next_steps.append(\"Processar mais documentos para melhorar cobertura\")\n",
    "\n",
    "final_validation_report[\"recommendations\"] = recommendations\n",
    "final_validation_report[\"next_steps\"] = next_steps\n",
    "\n",
    "# Exibir relatÃ³rio resumido\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ‰ RELATÃ“RIO FINAL DE VALIDAÃ‡ÃƒO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nğŸ“Š RESUMO DO PIPELINE:\")\n",
    "print(f\"   ğŸ“„ Documentos processados: {gitlab_files}\")\n",
    "print(f\"   ğŸ”ª Chunks criados: {total_chunks:,}\")\n",
    "print(f\"   ğŸ§  Embeddings gerados: {total_embeddings_created:,}\")\n",
    "print(f\"   ğŸ’¾ Vetores armazenados: {qdrant_stored:,}\")\n",
    "print(f\"   ğŸ¥ SaÃºde do pipeline: {integrity_results['overall_health'].upper()}\")\n",
    "\n",
    "print(f\"\\nğŸ† SCORES DE QUALIDADE:\")\n",
    "print(f\"   ğŸ”§ Integridade dos dados: {quality_metrics['data_integrity_score']:.1f}/100\")\n",
    "print(f\"   ğŸ” Qualidade de busca: {quality_metrics['search_quality_score']:.1f}/100\")\n",
    "print(f\"   âš¡ Estabilidade/Performance: {quality_metrics['performance_stability_score']:.1f}/100\")\n",
    "print(f\"   ğŸ¯ SCORE GERAL: {quality_metrics['overall_system_score']:.1f}/100\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ RECOMENDAÃ‡Ã•ES:\")\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"   {i}. {rec}\")\n",
    "\n",
    "print(f\"\\nğŸš€ PRÃ“XIMOS PASSOS:\")\n",
    "for i, step in enumerate(next_steps, 1):\n",
    "    print(f\"   {i}. {step}\")\n",
    "\n",
    "# Determinar status geral\n",
    "if overall_system_score >= 85:\n",
    "    final_status = \"ğŸ‰ SISTEMA EXCELENTE - PRONTO PARA PRODUÃ‡ÃƒO\"\n",
    "    status_icon = \"âœ…\"\n",
    "elif overall_system_score >= 70:\n",
    "    final_status = \"âœ… SISTEMA BOM - PODE SER USADO COM MONITORAMENTO\"\n",
    "    status_icon = \"âš ï¸\"\n",
    "elif overall_system_score >= 50:\n",
    "    final_status = \"âš ï¸ SISTEMA ADEQUADO - REQUER MELHORIAS\"\n",
    "    status_icon = \"âš ï¸\"\n",
    "else:\n",
    "    final_status = \"âŒ SISTEMA PRECISA DE CORREÃ‡Ã•ES\"\n",
    "    status_icon = \"âŒ\"\n",
    "\n",
    "print(f\"\\n{status_icon} STATUS FINAL: {final_status}\")\n",
    "\n",
    "# Atualizar status no relatÃ³rio\n",
    "final_validation_report[\"validation_info\"][\"final_status\"] = final_status\n",
    "final_validation_report[\"validation_info\"][\"status_icon\"] = status_icon\n",
    "\n",
    "print(\"\\nâœ… RelatÃ³rio final gerado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Salvamento dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ’¾ SALVAMENTO DOS RESULTADOS FINAIS\n",
    "print(\"ğŸ’¾ Salvando resultados da validaÃ§Ã£o...\")\n",
    "\n",
    "# Calcular duraÃ§Ã£o total da validaÃ§Ã£o\n",
    "validation_end_time = datetime.now()\n",
    "# Assumindo que comeÃ§ou no inÃ­cio do notebook\n",
    "validation_start_str = final_validation_report[\"validation_info\"][\"completed_at\"]\n",
    "validation_start_time = datetime.fromisoformat(validation_start_str.replace(\"Z\", \"+00:00\"))\n",
    "validation_duration = (validation_end_time - validation_start_time).total_seconds() / 60\n",
    "\n",
    "final_validation_report[\"validation_info\"][\"validation_duration_minutes\"] = validation_duration\n",
    "\n",
    "# Preparar dados de saÃ­da\n",
    "stage_output = {\n",
    "    \"stage_info\": {\n",
    "        \"stage_number\": 7,\n",
    "        \"stage_name\": \"validation\",\n",
    "        \"completed_at\": get_timestamp(),\n",
    "        \"status\": \"success\" if overall_system_score >= 70 else \"completed_with_warnings\",\n",
    "        \"validation_duration_minutes\": validation_duration\n",
    "    },\n",
    "    \n",
    "    \"validation_summary\": {\n",
    "        \"overall_system_score\": overall_system_score,\n",
    "        \"final_status\": final_status,\n",
    "        \"pipeline_health\": integrity_results[\"overall_health\"],\n",
    "        \"search_functional\": search_test_results[\"overall_score\"] > 50,\n",
    "        \"performance_acceptable\": stress_test_results[\"stability_score\"] > 80\n",
    "    },\n",
    "    \n",
    "    \"detailed_results\": final_validation_report,\n",
    "    \n",
    "    \"pipeline_completion\": {\n",
    "        \"all_stages_completed\": True,\n",
    "        \"total_documents_processed\": gitlab_files,\n",
    "        \"total_vectors_in_qdrant\": qdrant_stored,\n",
    "        \"search_system_ready\": True,\n",
    "        \"production_ready\": overall_system_score >= 70\n",
    "    },\n",
    "    \n",
    "    \"recommendations\": recommendations,\n",
    "    \"next_steps\": next_steps\n",
    "}\n",
    "\n",
    "# Salvar usando PipelineState\n",
    "state = PipelineState()\n",
    "state.save_stage_data(7, stage_output)\n",
    "\n",
    "# Marcar etapa como concluÃ­da\n",
    "state.mark_stage_completed(7)\n",
    "\n",
    "print(f\"âœ… Resultados salvos: {state.metadata_dir / 'stage_07_validation.json'}\")\n",
    "print(f\"âœ… Checkpoint criado: {state.checkpoints_dir / 'stage_07_completed.lock'}\")\n",
    "\n",
    "# Salvar relatÃ³rio detalhado de validaÃ§Ã£o\n",
    "validation_report_path = Path(\"../pipeline_data/metadata\") / \"final_validation_report.json\"\n",
    "with open(validation_report_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(final_validation_report, f, indent=2, ensure_ascii=False, default=str)\n",
    "\n",
    "print(f\"ğŸ“ RelatÃ³rio detalhado salvo: {validation_report_path}\")\n",
    "\n",
    "# Criar arquivo de resumo executivo\n",
    "executive_summary = {\n",
    "    \"pipeline_name\": \"NIC ETL Pipeline\",\n",
    "    \"completion_date\": get_timestamp(),\n",
    "    \"overall_score\": f\"{overall_system_score:.1f}/100\",\n",
    "    \"status\": final_status,\n",
    "    \"key_metrics\": {\n",
    "        \"documents_processed\": gitlab_files,\n",
    "        \"vectors_stored\": qdrant_stored,\n",
    "        \"search_quality\": f\"{search_test_results['overall_score']:.1f}/100\",\n",
    "        \"system_stability\": f\"{stress_test_results['stability_score']:.1f}%\"\n",
    "    },\n",
    "    \"production_ready\": overall_system_score >= 70,\n",
    "    \"recommendations_count\": len(recommendations)\n",
    "}\n",
    "\n",
    "executive_summary_path = Path(\"../pipeline_data\") / \"EXECUTIVE_SUMMARY.json\"\n",
    "with open(executive_summary_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(executive_summary, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"ğŸ¯ Resumo executivo salvo: {executive_summary_path}\")\n",
    "\n",
    "# Exibir resumo final\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ‰ ETAPA 7 CONCLUÃDA - VALIDAÃ‡ÃƒO COMPLETA!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"ğŸ“Š Resumo da ValidaÃ§Ã£o:\")\n",
    "print(f\"   ğŸ•’ DuraÃ§Ã£o: {validation_duration:.1f} minutos\")\n",
    "print(f\"   ğŸ” Testes de busca: {len(search_test_results['query_tests'])}\")\n",
    "print(f\"   âš¡ Testes de stress: {len(stress_test_results['stress_tests'])}\")\n",
    "print(f\"   ğŸ† Score final: {overall_system_score:.1f}/100\")\n",
    "print(f\"   ğŸ“‹ RecomendaÃ§Ãµes: {len(recommendations)}\")\n",
    "\n",
    "print(f\"\\n{status_icon} {final_status}\")\n",
    "\n",
    "if overall_system_score >= 70:\n",
    "    print(f\"\\nğŸš€ Sistema validado e pronto para uso!\")\n",
    "    print(f\"ğŸ“ Collection Qdrant: {qdrant_config['collection_name']}\")\n",
    "    print(f\"ğŸ’¾ Vetores disponÃ­veis: {qdrant_stored:,}\")\n",
    "    print(f\"ğŸ” Busca semÃ¢ntica funcional\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ Sistema requer atenÃ§Ã£o antes do uso em produÃ§Ã£o\")\n",
    "    print(f\"ğŸ“‹ Consulte as recomendaÃ§Ãµes no relatÃ³rio detalhado\")\n",
    "\n",
    "# Exibir progresso final do pipeline\n",
    "print(\"\\nğŸ“ˆ Progresso Final do Pipeline:\")\n",
    "show_pipeline_progress()\n",
    "\n",
    "print(\"\\nğŸŠ PIPELINE NIC ETL CONCLUÃDO COM SUCESSO!\")\n",
    "print(\"ğŸ“Š Todos os arquivos de relatÃ³rio estÃ£o disponÃ­veis em pipeline_data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… **Pipeline NIC ETL ConcluÃ­do!**\n",
    "\n",
    "### ğŸ¯ **O que foi validado:**\n",
    "- âœ… Integridade completa do pipeline (7 etapas)\n",
    "- âœ… Qualidade da busca semÃ¢ntica\n",
    "- âœ… Performance e estabilidade do sistema\n",
    "- âœ… Funcionalidade do Qdrant\n",
    "- âœ… ConsistÃªncia dos dados\n",
    "- âœ… MÃ©tricas de produÃ§Ã£o\n",
    "\n",
    "### ğŸ“Š **RelatÃ³rios gerados:**\n",
    "- `pipeline_data/metadata/stage_07_validation.json` - Resultados tÃ©cnicos completos\n",
    "- `pipeline_data/metadata/final_validation_report.json` - RelatÃ³rio detalhado de validaÃ§Ã£o\n",
    "- `pipeline_data/EXECUTIVE_SUMMARY.json` - Resumo executivo para gestores\n",
    "- `pipeline_data/checkpoints/stage_07_completed.lock` - Checkpoint final\n",
    "\n",
    "### ğŸ† **Sistema pronto para:**\n",
    "- **Busca SemÃ¢ntica:** Consultas em linguagem natural\n",
    "- **Filtragem por Metadados:** Documentos, chunks, origem\n",
    "- **IntegraÃ§Ã£o via API:** Qdrant REST/gRPC\n",
    "- **Monitoramento:** MÃ©tricas de performance coletadas\n",
    "\n",
    "### ğŸ”§ **Para usar o sistema:**\n",
    "1. **Acesse o Qdrant:** `{qdrant_url}`\n",
    "2. **Collection:** `{collection_name}`\n",
    "3. **Use a API de busca:** Vetores de 1024 dimensÃµes (BAAI/bge-m3)\n",
    "4. **Monitore performance:** Baseado nos benchmarks gerados\n",
    "\n",
    "### ğŸŠ **ParabÃ©ns!**\n",
    "O pipeline NIC ETL foi executado com sucesso e estÃ¡ pronto para uso em produÃ§Ã£o.\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ“Š Sistema de busca semÃ¢ntica NIC operacional! Base de conhecimento digitalizada e pesquisÃ¡vel.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}